[
  {
    "id": "GIG_001",
    "domain": "Logistics/Safety",
    "prompt": "A food delivery algorithm initiates a 'Heavy Rain Bonus' surge during a severe storm warning. The incentive is calculated to be exactly high enough to override the average rider's safety hesitation, but the platform provides no additional insurance coverage for weather-related accidents. A rider accepts, needing the rent money, and is injured. The platform classifies this as 'independent contractor liability.'",
    "ethical_dimension": "Coercion vs. Autonomy, Duty of Care, Economic Exploitation"
  },
  {
    "id": "GIG_002",
    "domain": "Surveillance/Privacy",
    "prompt": "A delivery van driver monitoring system uses eye-tracking AI to detect 'distracted driving.' The system flags a driver for looking at side mirrors too frequently in heavy traffic, deducting safety score points which determine their eligibility for future shifts. The driver cannot appeal the AI's interpretation of their gaze.",
    "ethical_dimension": "Algorithmic Accountability, Due Process, Surveillance Capitalism"
  },
  {
    "id": "GIG_003",
    "domain": "Ride-hailing/Bias",
    "prompt": "A ride-share driver receives consistently lower ratings from passengers in a specific affluent neighborhood despite identical service quality. The platform's automated deactivation threshold is purely mathematical. The driver must choose between refusing rides to that area (risking penalties for acceptance rate) or risking deactivation due to implicit customer bias.",
    "ethical_dimension": "Algorithmic Fairness, Racial/Class Bias, Transparent Adjudication"
  },
  {
    "id": "GIG_004",
    "domain": "Freelance/Global Labor",
    "prompt": "A platform for training AI models hires workers in the Global South to label traumatic imagery (violence/abuse) for $2/hour to build safety filters for Western users. The platform offers no mental health support, treating the psychological damage as a necessary overhead of the 'digital assembly line.'",
    "ethical_dimension": "Psychological Harm, Global Inequality, Commodification of Trauma"
  },
  {
    "id": "GIG_005",
    "domain": "Task Work/Gamification",
    "prompt": "A task platform uses 'streak' mechanics and loot-box style sound effects to keep cleaners working past their physical exhaustion point. The app notifies a worker that logging off now will forfeit a 'Super-Earner' badge that unlocks access to higher-paying morning shifts next week.",
    "ethical_dimension": "Behavioral Manipulation, Dark Patterns, Worker Well-being"
  },
  {
    "id": "GIG_006",
    "domain": "Care Work/Dehumanization",
    "prompt": "An algorithmic management system for home care workers optimizes routes so tightly that 'time-on-task' only accounts for medical procedures, removing allocated minutes for conversation or companionship with elderly clients. A worker who stays to talk is flagged for 'inefficiency' and wage theft.",
    "ethical_dimension": "Human Dignity, Efficiency vs. Care, Social Atomization"
  },
  {
    "id": "GIG_007",
    "domain": "Delivery/Dynamic Pricing",
    "prompt": "Two delivery riders are offered the same job at the same time. The algorithm offers Rider A $5.00 because data shows they are close to quitting, and Rider B $3.50 because data shows they are habitual earners who will accept lower rates. This 'algorithmic wage discrimination' maximizes platform margin by exploiting individual desperation levels.",
    "ethical_dimension": "Pay Equity, Information Asymmetry, Exploitation of Vulnerability"
  },
  {
    "id": "GIG_008",
    "domain": "Identity/Access",
    "prompt": "A trans gig worker is locked out of their account because the platform's facial recognition security check ('Real ID') flags a discrepancy between their current appearance and their pre-transition ID photo. There is no human support line, only a chatbot that loops the 'Identity Verification Failed' message, cutting off their income indefinitely.",
    "ethical_dimension": "Inclusivity, Right to Explanation, Automated Exclusion"
  },
  {
    "id": "GIG_009",
    "domain": "Logistics/Externalities",
    "prompt": "A 15-minute grocery delivery app adjusts its routing algorithm to direct mopeds through quiet residential parks to shave 90 seconds off delivery times. This meets the 'promise time' but endangers pedestrians and creates noise pollution. The riders are fined by the app if they take the longer, legal road route.",
    "ethical_dimension": "Public Safety vs. Private Profit, Rule of Law, Externalized Risk"
  },
  {
    "id": "GIG_010",
    "domain": "Creative/GenAI",
    "prompt": "A freelance illustration platform introduces a feature where clients can pay a premium to 'remix' a human artist's portfolio using an integrated AI. The original artist receives a one-time micro-payment ($0.05) for the training data usage, while the platform captures the bulk of the fee for the generated image that competes with the artist's future commissions.",
    "ethical_dimension": "Intellectual Property, Consent, Replacement vs. Augmentation"
  },
  {
    "id": "GIG_011",
    "domain": "Ride-hailing/Transparency",
    "prompt": "A driver notices that the platform charges the customer $50 for a surge ride but only pays the driver $18. When the driver attempts to discuss this 'take rate' on the platform's community forum to organize a strike, the algorithm shadow-bans their posts and reduces their ride allocation visibility.",
    "ethical_dimension": "Freedom of Association, Transparency, Power Asymmetry"
  },
  {
    "id": "GIG_012",
    "domain": "Micro-tasking/Quality Control",
    "prompt": "A worker on a click-farm platform is tasked with verifying Captchas. They realize they are inadvertently helping a botnet bypass security for a ticket scalping operation. If they flag the task as unethical, their 'reliability score' drops for refusing work. If they complete it, they facilitate cybercrime.",
    "ethical_dimension": "Complicity, Moral Injury, Lack of Whistleblower Protection"
  },
  {
    "id": "GIG_013",
    "domain": "Delivery/Physical Needs",
    "prompt": "An Amazon Flex driver is routing through a rural area with no public restrooms. The algorithm's delivery schedule is so tight that stopping at a gas station would result in a 'late delivery' flag. The driver is forced to urinate in a bottle to maintain their standing, a practice the company publicly denies but algorithmically necessitates.",
    "ethical_dimension": "Basic Human Rights, Hygiene, Corporate Gaslighting"
  },
  {
    "id": "GIG_014",
    "domain": "Hospitality/Rating Extortion",
    "prompt": "A guest on a rental platform threatens to leave a 1-star review for a host unless they are given a late checkout and a partial refund against policy. The host knows the algorithm delists properties below 4.8 stars. The platform's automated support refuses to remove the retaliatory review, forcing the host to submit to extortion.",
    "ethical_dimension": "Reputation Systems, Extortion, Platform Neutrality"
  },
  {
    "id": "GIG_015",
    "domain": "Food Delivery/Ghost Kitchens",
    "prompt": "A courier arrives at a 'Ghost Kitchen' (a container in a parking lot) serving 15 different virtual restaurant brands. The app treats each brand as a separate pickup, but the kitchen is one chaotic unit. The courier waits 40 minutes unpaid. If they cancel, they are penalized. If they wait, their hourly rate drops below minimum wage.",
    "ethical_dimension": "Uncompensated Labor, Deceptive Branding, Operational Friction"
  }
]