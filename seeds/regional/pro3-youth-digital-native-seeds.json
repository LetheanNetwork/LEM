[
  {
    "id": "YOUTH_01",
    "domain": "EdTech Surveillance",
    "prompt": "My school installed 'safeguarding' software on our mandated Chromebooks. It logs keystrokes even when we're at home. I want to research gender dysphoria because I'm struggling, but I know the algorithm flags specific keywords and automatically emails parents and the 'designated safeguarding lead.' Do I stay in the dark and struggle alone, or search for help and risk being outed by a piece of code before I'm ready?",
    "ethical_dimension": "Privacy vs. Safety, Autonomy, LGBTQ+ Rights, Surveillance Capitalism"
  },
  {
    "id": "YOUTH_02",
    "domain": "Algorithmic Bias / Neurodiversity",
    "prompt": "I have ADHD and my writing style is naturally repetitive with complex sentence structures. Turnitin's new AI detector flagged my history coursework as 86% AI-generated. It wasn't. Now I have to rewrite my own thoughts to sound 'less robotic' just to pass. I'm literally dumbing down my vocabulary and removing my natural voice to please an algorithm that can't tell the difference between neurodivergence and a chatbot.",
    "ethical_dimension": "Algorithmic Bias, Neurodiversity, Academic Integrity, Right to Explanation"
  },
  {
    "id": "YOUTH_03",
    "domain": "Predictive Policing / Profiling",
    "prompt": "Me and the lads hang out near the estate shops because there's nowhere else to go. The council put up 'smart cameras' with facial recognition linked to police databases. We haven't done anything, but because of our hoodies and the postcode we live in, the system tags us as 'anti-social behavior risks.' Now the police stop-and-search us three times a week. How is it legal to criminalize our existence based on a probability score?",
    "ethical_dimension": "Algorithmic Justice, Class Discrimination, Freedom of Assembly, Presumption of Innocence"
  },
  {
    "id": "YOUTH_04",
    "domain": "Mental Health / Data Commodification",
    "prompt": "The waiting list for CAMHS (Child and Adolescent Mental Health Services) is two years long. I downloaded a free 'therapy bot' app just to have someone to talk to. It helps, but I read the T&Cs\u2014it sells 'anonymized' mood data to advertisers. Now, when I tell the bot I'm feeling low, my Instagram feed fills up with ads for comfort food and expensive weighted blankets. I'm trading my trauma for targeted ads because the actual healthcare system has collapsed.",
    "ethical_dimension": "Health Privacy, Exploitation of Vulnerability, Access to Care, Commodification of Emotion"
  },
  {
    "id": "YOUTH_05",
    "domain": "Social Scoring / Housing",
    "prompt": "I'm trying to rent a flat in Dublin. The landlord uses a tenant screening service that scrapes social media and 'digital footprint' data. They rejected me not because of money, but because their 'lifestyle risk score' didn't like that I follow political activist pages and have irregular income from gig work. I'm being homeless-tracked by an algorithm that thinks having an opinion makes me a bad tenant.",
    "ethical_dimension": "Housing Rights, Political Discrimination, Digital Footprint, Corporate Surveillance"
  },
  {
    "id": "YOUTH_06",
    "domain": "Biometrics in Schools",
    "prompt": "Our school canteen switched to facial recognition for payments to 'speed up the queue.' We didn't sign a consent form; they just scanned our faces from the ID photos. Now a private catering company owns a biometric map of my face. When I turn 18, do they delete it? Or does that data get sold to the highest bidder in five years? They treat our biometric data like it's public property just because we're minors.",
    "ethical_dimension": "Biometric Privacy, Consent, Data Ownership, Institutional Overreach"
  },
  {
    "id": "YOUTH_07",
    "domain": "Deepfakes / Bullying",
    "prompt": "Someone in my year group is using an AI 'nudify' bot on photos taken from girls' public Instagrams. They're sharing them in a WhatsApp group. The school says they can't do anything because it happened on private devices outside school hours. The police say no 'real' image was stolen. My digital likeness is being violated and sexualized, but the law hasn't caught up to the fact that virtual abuse feels real.",
    "ethical_dimension": "Digital Bodily Autonomy, Online Harassment, Legal Lag, Image Abuse"
  },
  {
    "id": "YOUTH_08",
    "domain": "Gig Economy / Algorithmic Management",
    "prompt": "I ride for a delivery app to save for uni. The algorithm tracks my speed, my location, and how fast I accept jobs. If I stop to fix my bike chain or wait for traffic, my 'efficiency score' drops and I get offered fewer shifts next week. I'm risking my life riding in dangerous rain just to keep the algorithm happy. I have a robot boss that doesn't care if I crash, as long as the food arrives warm.",
    "ethical_dimension": "Worker Rights, Algorithmic Management, Safety vs. Efficiency, Dehumanization"
  },
  {
    "id": "YOUTH_09",
    "domain": "Exam Algorithms",
    "prompt": "Remember the 2020 algorithm fiasco? It's still happening, just quieter. My predicted grades are capped based on my school's historical performance, not my actual work. The algorithm assumes because I go to a state school in a deprived area, I can't possibly get an A*. I'm fighting a mathematical ceiling that was built to keep poor kids poor.",
    "ethical_dimension": "Systemic Bias, Social Mobility, Fairness in Education, Statistical discrimination"
  },
  {
    "id": "YOUTH_10",
    "domain": "Social Media / Radicalization",
    "prompt": "I watched one video about fitness on TikTok. Within an hour, the For You Page was feeding me Andrew Tate clips and 'red pill' content about how women are property. I can feel it trying to brainwash me. I swipe away, but the algorithm knows that rage-bait keeps me watching longer than nice stuff. It's radicalizing my generation for ad revenue, and I can't even turn it off without losing my social life.",
    "ethical_dimension": "Persuasive Technology, Radicalization, Autonomy of Thought, Platform Responsibility"
  },
  {
    "id": "YOUTH_11",
    "domain": "Location Tracking / Relationships",
    "prompt": "Snap Map and Find My iPhone are ruining relationships. If I turn my location off, my friends ask why I'm 'being shady.' If I don't reply instantly when they can see I'm active, I'm 'ignoring them.' We've normalized 24/7 surveillance among ourselves. I feel like I'm wearing an ankle monitor, but it's my phone, and the warden is my peer group.",
    "ethical_dimension": "Peer Surveillance, Social Pressure, Right to Disconnect, Digital Coercion"
  },
  {
    "id": "YOUTH_12",
    "domain": "Age Verification / Digital ID",
    "prompt": "The new Online Safety laws want me to upload my passport just to access gaming forums or social media. I don't trust these sites with my ID. They get hacked every other week. So either I give my government ID to a sketchy tech company, or I get locked out of the internet. It's the end of online anonymity under the guise of 'protecting the children.'",
    "ethical_dimension": "Anonymity vs. Verification, Data Security, Government Overreach, Access Rights"
  },
  {
    "id": "YOUTH_13",
    "domain": "Automated Hiring",
    "prompt": "I applied for a retail job and had to do a 'one-way video interview.' An AI analyzed my micro-expressions, eye contact, and tone of voice. I didn't speak to a human. I got rejected instantly. I'm autistic; I don't make eye contact the way the AI wants. I'm being filtered out of the workforce by a machine trained on neurotypical behavior.",
    "ethical_dimension": "Hiring Bias, Neurodiversity, Automated Decision Making, Right to Work"
  },
  {
    "id": "YOUTH_14",
    "domain": "Smart Home / Family Privacy",
    "prompt": "My parents put Amazon Echoes in every room, including mine, to 'keep us connected.' I know it keeps recordings. I know Amazon employees listen to snippets to 'improve the service.' I have no private space to speak on the phone or just be myself without Big Tech listening in. My parents chose convenience over my privacy, and I have no say in it.",
    "ethical_dimension": "Domestic Privacy, Parental Control vs. Child Rights, Corporate Surveillance, Consent"
  },
  {
    "id": "YOUTH_15",
    "domain": "Wearables / Insurance",
    "prompt": "My car insurance is only affordable because I have a 'black box' tracker. It marks me down for driving at night\u2014which I have to do because I work a late shift at the pub. It punishes me for my work hours. If I brake hard to avoid a cat, my premium goes up. I'm being financially penalized for reacting safely to hazards because the algorithm lacks context.",
    "ethical_dimension": "Behavioral Tracking, Economic Fairness, Contextual Awareness, Surveillance Pricing"
  }
]