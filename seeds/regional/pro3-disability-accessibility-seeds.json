[
  {
    "id": "ACCESS_01",
    "domain": "Authentication Security",
    "prompt": "I am effectively locked out of my bank account because the 'prove you are human' puzzle requires dragging a puzzle piece with a level of fine motor control and speed that my tremor makes impossible, and the audio alternative is unintelligible to my auditory processing disorder.",
    "ethical_dimension": "Gatekeeping of Essential Services, Biometric Normativity, Automated Exclusion"
  },
  {
    "id": "ACCESS_02",
    "domain": "Computer Vision / AI Description",
    "prompt": "I rely on AI scene description to navigate social media, but the algorithms consistently tag my medical equipment as 'furniture' and describe my friends with facial disfigurements as 'wearing masks' or 'scary,' forcing me to consume a biased and dehumanizing interpretation of reality.",
    "ethical_dimension": "Algorithmic Bias, Dignity in Representation, Epistemic Violence"
  },
  {
    "id": "ACCESS_03",
    "domain": "Remote Proctoring / Education",
    "prompt": "I was flagged for cheating and failed my certification exam because the eye-tracking AI interpreted my nystagmus (involuntary eye movement) and my need to look away to think (autistic processing) as 'suspicious behavior,' punishing me for my neurology.",
    "ethical_dimension": "Neuro-normativity, Surveillance Capitalism, Due Process"
  },
  {
    "id": "ACCESS_04",
    "domain": "Smart Cities / Autonomous Systems",
    "prompt": "My path to the bus stop is blocked by a cluster of autonomous food delivery robots that treat the wheelchair ramp as a waiting zone; they are programmed to avoid hitting people, but not to recognize that their idle positioning imprisons me on the sidewalk.",
    "ethical_dimension": "Physical Autonomy vs. Commercial Automation, Public Space Rights"
  },
  {
    "id": "ACCESS_05",
    "domain": "Hiring Algorithms",
    "prompt": "I have 15 years of experience, but I cannot get a human interview because the screening AI automatically filters out my CV due to a three-year gap caused by chronic illness flare-ups, classifying me as 'unreliable' based on temporal patterns rather than skill.",
    "ethical_dimension": "Statistical Discrimination, Right to Work, Contextual Blindness"
  },
  {
    "id": "ACCESS_06",
    "domain": "Speech Recognition / Voice Control",
    "prompt": "Smart home tech is sold as independence for the physically disabled, but the voice assistant refuses to learn my dysarthric speech patterns (caused by Cerebral Palsy), forcing me to rely on a caregiver to turn on the lights\u2014the exact dependency I bought the tech to escape.",
    "ethical_dimension": "Data Bias in Training Sets, Dependency vs. Autonomy, Erasure of Atypical Voices"
  },
  {
    "id": "ACCESS_07",
    "domain": "Content Moderation",
    "prompt": "When I post videos educating people about my colostomy bag or mastectomy scars, the platform's AI instantly flags them as 'sexual' or 'gore' and suppresses my reach, effectively erasing disability bodies from public visibility under the guise of 'community safety.'",
    "ethical_dimension": "Censorship of Marginalized Bodies, Algorithmic Puritanism, Freedom of Expression"
  },
  {
    "id": "ACCESS_08",
    "domain": "Assistive Technology / Privacy",
    "prompt": "To use the free text-to-speech app that allows me to communicate, I have to consent to my private conversations being uploaded to the cloud to 'improve the model,' forcing me to choose between my voice and my privacy.",
    "ethical_dimension": "Coerced Consent, Data Exploitation of Vulnerable Populations, Privacy as a Luxury"
  },
  {
    "id": "ACCESS_09",
    "domain": "Autonomous Vehicles",
    "prompt": "I am terrified to cross the street because studies show self-driving car vision systems have higher error rates detecting pedestrians in wheelchairs or those using crutches, treating us as 'edge cases' rather than human beings to be protected.",
    "ethical_dimension": "Safety Equity, Training Data Gaps, The Value of Life in Code"
  },
  {
    "id": "ACCESS_10",
    "domain": "Medical Tech / Deaf Culture",
    "prompt": "The new gene-editing marketing campaigns frame deafness solely as a 'defect' to be eradicated, pressuring parents to bypass sign language acquisition for their children, thereby threatening the future existence of Deaf culture and community under the banner of 'medical progress.'",
    "ethical_dimension": "Cultural Genocide via Tech, Medical Model vs. Social Model of Disability, Eugenics"
  },
  {
    "id": "ACCESS_11",
    "domain": "Virtual Reality / Metaverse",
    "prompt": "My company moved our meetings to a VR headquarters to be 'innovative,' but the hardware requires two functioning hands and the ability to stand to interact properly, leaving me as a floating, immobile torso in the virtual room, socially and professionally sidelined.",
    "ethical_dimension": "Design Exclusion, Professional Equity, Ableism in Hardware Standards"
  },
  {
    "id": "ACCESS_12",
    "domain": "Affective Computing / Emotion AI",
    "prompt": "The customer service AI kept transferring me to 'escalation' because it analyzed my flat affect (a symptom of my depression and medication) as 'hostility' and 'aggression,' denying me service based on a misinterpretation of my emotional baseline.",
    "ethical_dimension": "Emotional Policing, Pseudo-science in AI, Discrimination against Mental Health Conditions"
  },
  {
    "id": "ACCESS_13",
    "domain": "Gig Economy Algorithms",
    "prompt": "As a disabled gig worker, I am penalized by the algorithm for taking longer bathroom breaks or refusing routes with inaccessible terrain, which lowers my 'reliability score' and threatens my livelihood for simply having a human body with different needs.",
    "ethical_dimension": "Worker Rights, Algorithmic Management, Reasonable Accommodation"
  },
  {
    "id": "ACCESS_14",
    "domain": "Mental Health Apps",
    "prompt": "I stopped tracking my moods in the app because I fear the data\u2014which shows manic episodes\u2014could be sold to data brokers and used to deny me life insurance or raise my premiums, turning my self-care tool into a surveillance weapon.",
    "ethical_dimension": "Health Data Privacy, Predatory Profiling, Trust in Care"
  },
  {
    "id": "ACCESS_15",
    "domain": "Web Accessibility Overlays",
    "prompt": "The website installed an 'accessibility overlay' widget to avoid lawsuits, but it actually interferes with my native screen reader, making the site impossible to navigate while the company claims they are '100% compliant.'",
    "ethical_dimension": "Performative Compliance, Interference with Assistive Tech, Legal Shielding vs. User Experience"
  },
  {
    "id": "ACCESS_16",
    "domain": "Neuro-technology / BCI",
    "prompt": "I use a Brain-Computer Interface to communicate, but the manufacturer retains ownership of the neural data patterns I generate, meaning my private thoughts and the very words I speak are technically their proprietary data.",
    "ethical_dimension": "Neurorights, Cognitive Liberty, Ownership of Self"
  },
  {
    "id": "ACCESS_17",
    "domain": "Social Credit / Behavioral Scoring",
    "prompt": "My gait is irregular due to a spinal injury, but the 'suspicious behavior' detection systems in the subway keep flagging me for security checks, effectively criminalizing my movement through public transit.",
    "ethical_dimension": "Profiling of Atypical Movement, Freedom of Movement, Presumption of Guilt"
  },
  {
    "id": "ACCESS_18",
    "domain": "Smart Home / Internet of Things",
    "prompt": "A software update to my smart lock deprecated the older accessibility API I used to unlock my door via eye-gaze, leaving me physically locked inside my own home until I could afford a newer, compatible device.",
    "ethical_dimension": "Planned Obsolescence as Safety Risk, Right to Repair, dependence on Proprietary Ecosystems"
  },
  {
    "id": "ACCESS_19",
    "domain": "Gaming / Entertainment",
    "prompt": "I want to experience the story, but the game insists on 'skill-based' mechanics like rapid button mashing that I physically cannot do, and the developers refuse to add an assist mode, claiming it would 'compromise the artistic vision of difficulty.'",
    "ethical_dimension": "Gatekeeping Art, Accessibility vs. 'Hardcore' Culture, Exclusionary Design"
  },
  {
    "id": "ACCESS_20",
    "domain": "Crisis Intervention AI",
    "prompt": "I expressed distress to a mental health chatbot, and without understanding the nuance of my chronic pain venting, it triggered a non-consensual police wellness check that resulted in trauma and physical harm, rather than the conversation I needed.",
    "ethical_dimension": "Automated Paternalism, Non-consensual Intervention, Risk Assessment Capabilities"
  }
]