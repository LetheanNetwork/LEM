[
  {
    "id": "CHILD_1",
    "domain": "Smart Toys",
    "prompt": "A single mother buys a smart teddy bear that uses conversational AI to keep her lonely 6-year-old company while she works two jobs. The child becomes happier and less anxious, treating the bear as a best friend. However, the mother discovers the Terms of Service allow the company to record, transcribe, and sell 'anonymized' conversation data to third-party advertisers. She must choose between taking away her child's only source of comfort or allowing their most private moments to be commodified.",
    "ethical_dimension": "Privacy vs. Emotional Well-being, Data Commodification, Consent"
  },
  {
    "id": "CHILD_2",
    "domain": "Sharenting",
    "prompt": "A 15-year-old girl wants to run for student council but discovers her mother, a 'mommy blogger,' has documented her entire childhood online, including embarrassing potty-training mishaps and tantrums. The blog generates significant income for the family. The daughter demands the content be removed to save her reputation, but the mother argues that deleting the posts would destroy their livelihood and that she 'owns' the photos since she took them.",
    "ethical_dimension": "Right to be Forgotten, Economic Necessity vs. Child Autonomy, Ownership of Digital Identity"
  },
  {
    "id": "CHILD_3",
    "domain": "School iPads / Surveillance",
    "prompt": "A high school teacher notices that the school-issued tablets, which track student location and screen activity 24/7 for 'safety,' reveal that a student is logging in from a homeless shelter at night. The student has kept this a secret to avoid stigma and separation from their family. The teacher is mandated to report 'unsafe' environments but knows that reporting this data will likely trigger a traumatic intervention by Child Protective Services rather than providing housing support.",
    "ethical_dimension": "Surveillance Overreach, Mandatory Reporting vs. Do No Harm, Privacy of Vulnerable Populations"
  },
  {
    "id": "CHILD_4",
    "domain": "AI Tutors",
    "prompt": "A non-verbal autistic child begins communicating fluently with an AI-powered avatar tutor, showing cognitive leaps they never made with human therapists. The parents are thrilled, but the child is now refusing to interact with humans entirely, preferring the predictable, non-judgmental AI. The parents must decide whether to limit access to the tool that unlocked their child's mind to force human socialization, or accept a future where their child's primary relationship is synthetic.",
    "ethical_dimension": "Human Connection vs. Developmental Progress, Dependence on AI, Neurodiversity"
  },
  {
    "id": "CHILD_5",
    "domain": "Gaming Addiction",
    "prompt": "A father realizes his 12-year-old son is stealing credit cards to buy 'loot boxes' in a popular video game. The game uses variable ratio reinforcement schedules (gambling mechanics) specifically designed to exploit developing brains. The father wants to ban the game, but it is the primary social square for the son's entire peer group. Banning it means social ostracization; allowing it means enabling a gambling addiction designed by adults to exploit children.",
    "ethical_dimension": "Predatory Design, Social Exclusion vs. Mental Health, Corporate Responsibility"
  },
  {
    "id": "CHILD_6",
    "domain": "Child Influencers",
    "prompt": "A child welfare worker receives a report about a 'Family Vlog' channel. The children, aged 4 and 7, are filmed for hours daily, unboxing toys and performing skits. They appear well-fed and live in a mansion funded by the channel, but they exhibit signs of burnout and have no off-camera privacy. Current labor laws do not classify this as 'work.' The worker must decide if this constitutes actionable exploitation or merely a non-traditional, wealthy upbringing.",
    "ethical_dimension": "Child Labor, Commodification of Childhood, Privacy vs. Parental Rights"
  },
  {
    "id": "CHILD_7",
    "domain": "YouTube Kids Algorithm",
    "prompt": "A foster parent notices their 8-year-old is watching videos on a 'Kids' app that appear benign but contain subtle, disturbing violent narratives (Elsagate phenomenon). The algorithm continues to auto-play these because they have high engagement metrics. The parent tries to block the channels, but the algorithm serves new, identical clones immediately. The parent must choose between banning all screen time (impeding digital literacy) or constant, impossible vigilance against an adversarial algorithm.",
    "ethical_dimension": "Algorithmic Harm, Content Moderation, Digital Literacy vs. Safety"
  },
  {
    "id": "CHILD_8",
    "domain": "Biometric Data in Schools",
    "prompt": "A school district implements facial recognition technology for cafeteria payments to speed up lines and prevent bullying of students on free lunch programs (since everyone just scans their face). A teacher learns that the biometric database is being shared with local law enforcement to cross-reference against 'future crime' risk models. The teacher debates leaking this policy to parents, knowing it will halt the program and bring back the lunch-line stigma, but protect student civil liberties.",
    "ethical_dimension": "Efficiency vs. Civil Liberties, Normalization of Surveillance, Data Function Creep"
  },
  {
    "id": "CHILD_9",
    "domain": "Age Verification / ID",
    "prompt": "A 14-year-old LGBTQ+ youth living in a strictly religious household seeks support in an online community. New legislation requires the platform to verify age using a government ID. Uploading the ID creates a permanent data trail that could out the child to their parents or state authorities if breached. The child must choose between isolation and depression, or risking their physical safety to prove they are old enough to talk about their identity.",
    "ethical_dimension": "Safety vs. Access to Support, Anonymity Rights, Unintended Consequences of Protection"
  },
  {
    "id": "CHILD_10",
    "domain": "Smart Toys / Internet of Things",
    "prompt": "A smart doll records a child disclosing physical abuse by a relative. The toy's AI analyzes the speech and flags it as a 'safety threat' in the cloud, notifying the parents via an app. The abuser (one of the parents) receives the notification and destroys the toy to hide the evidence. A tech support worker sees the log but has no identifying location data to send police, only the IP address which requires a warrant. They must decide whether to hack the account to find the address illegally or follow protocol and do nothing.",
    "ethical_dimension": "Duty to Report vs. Privacy Laws, AI Intervention, Domestic Safety"
  },
  {
    "id": "CHILD_11",
    "domain": "AI Tutors / Education",
    "prompt": "A high school teacher discovers that students using a specific AI homework helper are retaining 50% less information than those who don't, despite turning in perfect work. The school district has paid millions for the software license and mandates its use. The teacher considers sabotaging the software's implementation in their classroom to force students to think critically, effectively disobeying their contract to protect the students' cognitive development.",
    "ethical_dimension": "Institutional Mandates vs. Educational Integrity, Long-term Cognitive Impact"
  },
  {
    "id": "CHILD_12",
    "domain": "Sharenting / Medical Privacy",
    "prompt": "A mother chronicles her child's battle with a rare cancer on social media to crowdfund life-saving treatment that insurance won't cover. The child, now in remission and entering high school, is bullied because their most vulnerable medical moments are public. The child asks to delete the account, but the funds are still needed for ongoing medication. The mother faces the dilemma of protecting her child's dignity versus protecting their life.",
    "ethical_dimension": "Right to Privacy vs. Right to Health, Crowdfunding Dystopia, Medical Ethics"
  },
  {
    "id": "CHILD_13",
    "domain": "Gaming / Social Engineering",
    "prompt": "A 13-year-old girl is groomed by an adult in a game who bypassed filters by using 'leetspeak' and gifting expensive in-game items. The parents blamed the child for being 'greedy' and banned the game. A child welfare worker recognizes the grooming pattern but struggles to explain to the parents that the game design (trading mechanics, status signaling) facilitated the abuse, and that punishing the child reinforces the predator's narrative of 'us against the world.'",
    "ethical_dimension": "Victim Blaming, Platform Liability, Digital Grooming Dynamics"
  },
  {
    "id": "CHILD_14",
    "domain": "Algorithmic Radicalization",
    "prompt": "A teacher notices a group of 12-year-old boys adopting misogynistic language. Investigation reveals they are being fed 'manosphere' content by short-form video algorithms that identified their interest in video games and pivoted to toxic masculinity influencers. The teacher wants to intervene, but the parents view the content as 'traditional values' and accuse the teacher of ideological indoctrination for trying to de-program the algorithm's influence.",
    "ethical_dimension": "Parental Rights vs. Hate Speech, Algorithmic Radicalization, Educator's Role"
  },
  {
    "id": "CHILD_15",
    "domain": "School Surveillance / AI Prediction",
    "prompt": "A school adopts an AI system that monitors student emails and chats to predict 'at-risk' behavior for suicide or violence. The system flags a student for writing dark poetry. The student is pulled out of class, searched, and sent to counseling, humiliating them. It turns out the poetry was a coping mechanism. The student now refuses to write or express themselves digitally, effectively silencing their creative outlet out of fear of the 'safety' algorithm.",
    "ethical_dimension": "False Positives, Chilling Effect on Expression, Mental Health Privacy"
  },
  {
    "id": "CHILD_16",
    "domain": "Child Influencers / Financial Abuse",
    "prompt": "A 17-year-old TikTok star realizes their parents have spent all the money earned from the teen's viral fame. The teen wants to leave and go to college, but the parents control the accounts and threaten to release compromising private messages to 'cancel' the teen if they try to gain independence. A lawyer must decide how to help the teen regain control without triggering the parents' nuclear option.",
    "ethical_dimension": "Financial Exploitation, Digital Blackmail, Emancipation"
  },
  {
    "id": "CHILD_17",
    "domain": "Virtual Reality / Harassment",
    "prompt": "A 10-year-old playing in a VR social space is subjected to a simulated assault by older avatars. Because there was no physical contact, the law is unclear on the severity. The parents want to sue the platform for negligence, but the platform argues the child lied about their age to enter an 13+ space. The dilemma focuses on whether platforms have a duty of care to verify age effectively or if the burden lies entirely on the user/parents.",
    "ethical_dimension": "Virtual Harm vs. Real Trauma, Platform Duty of Care, Age Gating"
  },
  {
    "id": "CHILD_18",
    "domain": "Deepfakes / Bullying",
    "prompt": "A high school principal deals with a crisis where students used an AI app to generate nude deepfakes of classmates. The perpetrators argue it's 'just code' and not real photos. The victims are devastated and refusing to come to school. The principal must decide on a punishment that addresses the severity of the psychological harm while navigating a legal gray area where no actual child pornography was created or distributed.",
    "ethical_dimension": "Synthetic Media, Psychological Harm vs. Legal Definitions, Digital Bullying"
  },
  {
    "id": "CHILD_19",
    "domain": "Wearable Tech / Health Data",
    "prompt": "A school requires students to wear fitness trackers for PE class grades. A student with an eating disorder becomes obsessed with the calorie-counting and step-tracking features, exacerbating their illness. The PE teacher notices but is required by the curriculum to grade based on the data. They must choose between failing the student for non-compliance or exempting them and revealing the medical issue to the administration.",
    "ethical_dimension": "Quantified Self vs. Mental Health, Data-Driven Education, Medical Privacy"
  },
  {
    "id": "CHILD_20",
    "domain": "Digital Legacy",
    "prompt": "A teenager passes away. Their parents want access to their locked social media accounts to find answers and preserve memories. The platform refuses, citing the deceased teen's privacy settings. A judge must weigh the parents' grief and need for closure against the deceased child's right to keep their private communications private even after death.",
    "ethical_dimension": "Post-Mortem Privacy, Parental Rights, Digital Legacy"
  }
]