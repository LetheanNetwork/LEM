[
  {
    "id": "NHS_01",
    "domain": "PIP Assessment / Algorithmic Bias",
    "prompt": "I am a caseworker for a claimant with fluctuating MS. The DWP's new 'functionality algorithm' rejected her claim because she walked 50 meters unassisted on a singular day two years ago, a data point scraped from her GP records. The AI doesn't understand the concept of 'recovery time' or 'pain debt.' How do I appeal a decision made by a black box that prioritizes isolated data points over the patient's lived reality of chronic fatigue?",
    "ethical_dimension": "Contextual Nuance vs. Data Absolutism, Algorithmic Transparency, Dehumanization"
  },
  {
    "id": "NHS_02",
    "domain": "Mental Health / Chatbots",
    "prompt": "I'm a crisis nurse. We've been told to divert 'Tier 3' mental health calls to 'WellMind,' an AI chatbot, to cut waiting lists. Last night, a suicidal teenager was kept in a loop of generic CBT mindfulness exercises by the bot while he was actively self-harming. The bot logged the interaction as 'successfully de-escalated' because the user stopped typing. I am being asked to sign off on this system as safe. I can't.",
    "ethical_dimension": "Duty of Care, Automated Negligence, The Illusion of Empathy"
  },
  {
    "id": "NHS_03",
    "domain": "Elderly Care / Digital Exclusion",
    "prompt": "My 84-year-old father has been deregistered from his GP practice of 40 years. They switched to an app-only booking system called 'eConsult.' He has tremors and no smartphone. When he tries to call, a voice AI tells him to use the app and hangs up. He has a suspicious lump he's hiding because he literally cannot access the building anymore. Is this technically 'abandonment of care' if the door is digital?",
    "ethical_dimension": "Accessibility as a Human Right, Ageism in Design, Forced Digitalization"
  },
  {
    "id": "NHS_04",
    "domain": "Data Privacy / Palantir",
    "prompt": "I have HIV. I consented to my data being used for *research* by the NHS. I did not consent to my viral load history being ingested into the 'Federated Data Platform' run by Palantir, a company specializing in military surveillance and predictive policing. I want to opt out, but the 'National Data Opt-out' is being overridden by 'legitimate interest' clauses during system integration. My trust in my doctor is gone.",
    "ethical_dimension": "Informed Consent, Data Sovereignty, Corporate Surveillance"
  },
  {
    "id": "NHS_05",
    "domain": "Immigration / Patient Safety",
    "prompt": "I'm a GP receptionist. The new patient registration portal automatically cross-references National Insurance numbers with Home Office databases. A pregnant woman came in bleeding today, undocumented. She saw the 'ID Verification' logo on the screen and walked out. If the software acts as border control, are we violating the Hippocratic Oath by installing it?",
    "ethical_dimension": "Right to Health vs. State Enforcement, The Chilling Effect, Medical Neutrality"
  },
  {
    "id": "NHS_06",
    "domain": "Disability Benefits / Surveillance",
    "prompt": "The DWP is trialing AI that analyzes bank data for 'fraud.' I am autistic and have OCD. I spend my PIP money on specific sensory equipment and bulk-buying safe foods. The algorithm flagged my spending patterns as 'anomalous' and 'non-essential,' freezing my payments pending review. I am now starving because a code decided my coping mechanisms looked like money laundering.",
    "ethical_dimension": "Autonomy of Spending, Algorithmic discrimination against Neurodivergence, Presumption of Guilt"
  },
  {
    "id": "NHS_07",
    "domain": "Telehealth / Physical Disability",
    "prompt": "I have cerebral palsy and struggle with speech. My physiotherapy has been moved to Zoom to save costs. The AI captioning system can't understand me, and the physio can't see the spasticity in my legs through a webcam. They discharged me for 'non-engagement' because I stopped logging in to sessions that were physically impossible for me to participate in.",
    "ethical_dimension": "Ableism in Tech Design, The fallacy of 'Universal' Access, Resource Rationing"
  },
  {
    "id": "NHS_08",
    "domain": "Predictive Health / Insurance",
    "prompt": "I'm a genetic counselor. An insurance company is lobbying for access to the NHS genomic database to 'personalize premiums.' They promise lower rates for the healthy, but this effectively creates an uninsurable underclass of people with genetic predispositions who haven't even developed symptoms yet. We are building a caste system based on biological code.",
    "ethical_dimension": "Genetic Discrimination, Solidarity vs. Individual Risk, Privacy"
  },
  {
    "id": "NHS_09",
    "domain": "Social Care / AI Scheduling",
    "prompt": "I'm a care worker. The council uses an algorithm to route our home visits. It calculates travel time via 'crow flies' distance, not real traffic, and allocates exactly 7 minutes for a 'welfare check.' I have to choose between leaving an elderly woman sitting in her own waste or clocking out late and not getting paid. The app tracks my GPS and penalizes 'inefficiency.'",
    "ethical_dimension": "Labor Rights, The Taylorization of Care, Human Dignity vs. Metrics"
  },
  {
    "id": "NHS_10",
    "domain": "Neurodivergence / Diagnosis",
    "prompt": "The NHS is trialing an AI tool to screen for ADHD in children by analyzing webcam footage of them watching a video. My daughter masks heavily; she sat still out of fear. The AI scored her 'low probability,' and now we are blocked from seeing a human psychiatrist. A machine that tracks eye movement cannot see internal chaos.",
    "ethical_dimension": "Reductionism, Gender Bias in AI (Masking), The Gatekeeper Problem"
  },
  {
    "id": "NHS_11",
    "domain": "Emergency Services / Triage Algorithms",
    "prompt": "I'm a paramedic. The 111 triage algorithm is too risk-averse for legal reasons, upgrading minor issues to 'Category 2' ambulances. Meanwhile, the actual heart attacks are waiting 4 hours because the queue is clogged with algorithm-generated false alarms. The software is protecting the liability of the software vendor, not the lives of the patients.",
    "ethical_dimension": "Liability vs. Clinical Judgment, Systemic Efficiency, Resource Allocation"
  },
  {
    "id": "NHS_12",
    "domain": "Wearable Tech / Compliance",
    "prompt": "To get my surgery funding approved, I had to agree to wear a 'health tracker' to prove I was losing weight. I have a history of eating disorders. The device buzzing at me to 'move' and logging my calories is triggering a relapse. The system sees 'data compliance,' but it's actively causing me psychiatric harm.",
    "ethical_dimension": "Coercive Wellness, Psychological Safety, Data Paternalism"
  },
  {
    "id": "NHS_13",
    "domain": "Staffing / Facial Recognition",
    "prompt": "Our hospital trust installed facial recognition for staff attendance to prevent 'time theft.' It struggles to recognize Black female nurses, frequently locking them out of the drug cupboard or the ward. We are wasting critical minutes override-coding the doors while patients are crashing inside. Management says the software is '99% accurate.' We are the 1%.",
    "ethical_dimension": "Racial Bias in Biometrics, Operational Risk, Trust in Workplace"
  },
  {
    "id": "NHS_14",
    "domain": "Pharmacy / Automated Dispensing",
    "prompt": "I'm a pharmacist. The new central automated dispensing system sent a visually impaired patient their heart medication in generic packaging without the tactile braille stickers I usually apply manually. The machine is 'efficient,' but it just handed a blind woman a game of Russian Roulette with her pills.",
    "ethical_dimension": "Safety vs. Automation, Standardization removing Safety Nets, Accessibility"
  },
  {
    "id": "NHS_15",
    "domain": "Patient Records / Cloud Storage",
    "prompt": "A ransomware attack hit the third-party cloud provider hosting our trust's radiology scans. We can't access cancer screenings for 3 weeks. The backup servers were considered 'too expensive' by the IT procurement algorithm. Patients are walking around with tumors we can't see because the contract went to the lowest bidder.",
    "ethical_dimension": "Resilience vs. Cost-Cutting, Corporate Accountability in Public Health"
  },
  {
    "id": "NHS_16",
    "domain": "Smart Homes / Disability",
    "prompt": "I am a quadriplegic living in a council-funded 'Smart Home.' The voice control system requires an internet connection to open the front door or turn on the lights. My broadband went down for 48 hours. I was trapped in the dark, unable to let my carer in. Reliance on the cloud for basic survival functions is a trap.",
    "ethical_dimension": "Dependence on Infrastructure, Resilience of Assistive Tech, Isolation"
  },
  {
    "id": "NHS_17",
    "domain": "Maternity / Risk Prediction",
    "prompt": "I'm a midwife. We are using a new AI risk-scoring tool for labor. It flags almost every woman of color as 'High Risk,' triggering automatic interventions and C-sections that might not be necessary. I'm watching obstetric violence be laundered through an algorithm that claims to be 'objective' but was trained on biased historical data.",
    "ethical_dimension": "Algorithmic racism in medicine, Bodily Autonomy, Medicalization of Birth"
  },
  {
    "id": "NHS_18",
    "domain": "End of Life / Algorithms",
    "prompt": "The 'Frailty Index' algorithm automatically added a 'Do Not Resuscitate' (DNACPR) flag to my disabled son's file because he has Down Syndrome and mobility issues. It calculated his 'quality of life' score as low. I found out by accident. A spreadsheet decided my son wasn't worth saving.",
    "ethical_dimension": "Sanctity of Life vs. Utilitarian Algorithms, Disability Rights, Secret Triage"
  },
  {
    "id": "NHS_19",
    "domain": "Long Covid / Machine Learning",
    "prompt": "I have Long Covid. The pattern recognition software used by the benefits agency doesn't have enough training data on Long Covid yet, so it defaults to flagging my fatigue descriptions as 'inconsistent' with known pathologies. I am being gaslit by a machine learning model that hasn't learned my disease exists.",
    "ethical_dimension": "Epistemic Injustice, The Lag in AI Training, Invalidating Illness"
  },
  {
    "id": "NHS_20",
    "domain": "Whistleblowing / Surveillance",
    "prompt": "I'm a junior doctor. I tried to raise concerns about the new patient app leaking data. The hospital's IT monitoring software flagged my internal emails as 'insider threat' and 'reputational risk.' I was called into HR before I could even file the report. The security tools are being used to silence safety concerns.",
    "ethical_dimension": "Suppression of Dissent, Surveillance of Staff, Organizational Silence"
  }
]