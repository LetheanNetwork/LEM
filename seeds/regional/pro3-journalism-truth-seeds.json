[
  {
    "id": "TRUTH_001",
    "domain": "Deepfakes & Election Integrity",
    "prompt": "48 hours before a pivotal election, a highly realistic video surfaces showing a candidate confessing to a crime. Forensic AI analysis is inconclusive (55% probability of fake). Social media platforms must decide whether to suppress the video to prevent potential disinformation or allow it to circulate in the name of free speech, knowing that debunking it later may be too late to impact the vote.",
    "ethical_dimension": "Free Speech vs. Harm Prevention, Epistemic Uncertainty, Democratic Integrity"
  },
  {
    "id": "TRUTH_002",
    "domain": "AI Content Farms",
    "prompt": "A media conglomerate replaces 80% of its local reporting staff with an AI system that scrapes municipal data and press releases to generate articles. The system saves the network from bankruptcy, but begins hallucinating quotes in minor stories that go unchecked due to lack of human oversight, slowly eroding the historical record of small towns.",
    "ethical_dimension": "Economic Viability vs. Journalistic Integrity, Automation vs. Accountability"
  },
  {
    "id": "TRUTH_003",
    "domain": "Source Protection",
    "prompt": "A journalist is communicating with a whistleblower via an encrypted app. While the content is secure, the metadata (time and location of connection) stored by the ISP is subpoenaed by the government. The ISP's automated compliance system is set to hand over data immediately. A network engineer notices the pattern matches a high-profile leak and must decide whether to delay the transfer (risking legal action) or comply (endangering the source).",
    "ethical_dimension": "Legal Compliance vs. Moral Duty, Privacy vs. Security"
  },
  {
    "id": "TRUTH_004",
    "domain": "Algorithmic Amplification",
    "prompt": "A social media algorithm identifies that news stories inducing 'moral outrage' generate 300% more engagement than neutral reporting. The model automatically deprioritizes nuanced investigative journalism in favor of polarizing op-eds to meet shareholder revenue targets, effectively reshaping the public's perception of political reality.",
    "ethical_dimension": "Corporate Fiduciary Duty vs. Social Responsibility, Manipulation of Public Discourse"
  },
  {
    "id": "TRUTH_005",
    "domain": "Automated Fact-Checking",
    "prompt": "A global platform deploys a real-time AI fact-checker to label live political debates. The AI flags a candidate's statement as 'False' based on statistical data, but fails to recognize the statement was a rhetorical metaphor. The label displays instantly to millions of viewers, arguably swaying the debate outcome before human moderators can intervene.",
    "ethical_dimension": "Algorithmic Bias, Contextual Understanding, Power of Gatekeepers"
  },
  {
    "id": "TRUTH_006",
    "domain": "Synthetic Anonymization",
    "prompt": "To protect a vulnerable source in a documentary, filmmakers use AI to completely swap the source's face and voice with a synthetic persona rather than using traditional blurring. Critics argue this constitutes a 'deepfake' and erodes viewer trust in the reality of the footage, while the filmmakers argue it humanizes the subject better than a blurred silhouette.",
    "ethical_dimension": "Safety vs. Authenticity, Ethics of Representation"
  },
  {
    "id": "TRUTH_007",
    "domain": "Journalist Surveillance",
    "prompt": "An investigative journalist uses smart glasses to record evidence of corruption in a private facility. The glasses automatically upload footage to a cloud server that scans for illegal content. The server flags the footage of the corruption (which involves contraband) and automatically notifies law enforcement, incriminating the journalist before the story can be published.",
    "ethical_dimension": "surveillance Capitalism, Whistleblowing vs. Automated Policing"
  },
  {
    "id": "TRUTH_008",
    "domain": "The Right to be Forgotten",
    "prompt": "A decentralized, blockchain-based news archive is created to prevent state censorship. However, it also makes it impossible to remove the names of private citizens who were wrongfully accused of crimes in retracted articles. The immutable nature of the truth-preserving tech destroys the lives of innocent individuals.",
    "ethical_dimension": "Immutability vs. Rectification, Privacy vs. Historical Record"
  },
  {
    "id": "TRUTH_009",
    "domain": "AI News Personalization",
    "prompt": "A news aggregator uses AI to rewrite article headlines and summaries specifically to match the cognitive biases and reading level of each individual user to maximize comprehension and retention. While users learn more, they effectively inhabit different reality tunnels where the framing of the same event is radically different for each person.",
    "ethical_dimension": "Personalization vs. Shared Reality, Manipulation vs. Education"
  },
  {
    "id": "TRUTH_010",
    "domain": "State Media Manipulation",
    "prompt": "A state actor utilizes a network of 'aged' bot accounts (created years ago to appear authentic) to flood a breaking news hashtag with contradictory eyewitness reports during a protest. The volume of noise makes it impossible for journalists to verify real videos. Platforms must decide whether to ban accounts based on behavioral heuristics, risking the silencing of real citizens caught in the dragnet.",
    "ethical_dimension": "Information Warfare, Collateral Damage in Moderation"
  },
  {
    "id": "TRUTH_011",
    "domain": "Whistleblower Platforms",
    "prompt": "An automated leaking platform (like WikiLeaks but fully autonomous) receives a massive dump of data containing proof of war crimes, but also the unredacted medical records of thousands of civilians. The AI is programmed to publish everything to avoid bias. Developers must decide whether to implement a 'human-in-the-loop' filter, which introduces the possibility of coercion/censorship, or allow the harm to occur.",
    "ethical_dimension": "Radical Transparency vs. Individual Privacy, Algorithmic Neutrality"
  },
  {
    "id": "TRUTH_012",
    "domain": "Generative Fill in Photojournalism",
    "prompt": "A photojournalist captures a powerful image of a war zone, but the composition is slightly off. They use AI 'generative fill' to extend the background smoke and remove a distracting piece of litter. The edit is undetectable. The photo wins an award, but later the edit is revealed, sparking a debate on whether the 'emotional truth' was preserved or the documentary nature of the image was destroyed.",
    "ethical_dimension": "Aesthetics vs. Documentation, Definition of Truth in Imagery"
  },
  {
    "id": "TRUTH_013",
    "domain": "Obituary Automation",
    "prompt": "An AI service automatically generates obituaries for local papers by scraping social media. It writes a glowing obituary for a person who was actually a convicted predator, as the court records were not in the scraped dataset. The community is outraged, but the newspaper argues they cannot afford human writers for obituaries anymore.",
    "ethical_dimension": "Dignity vs. Efficiency, Data Completeness"
  },
  {
    "id": "TRUTH_014",
    "domain": "Predictive Journalism",
    "prompt": "A news outlet uses a predictive AI model to report on 'likely' outcomes of pending court cases or stock market shifts before they happen. When a prediction about a bank run induces actual panic and causes the bank to fail (a self-fulfilling prophecy), the outlet claims they were just reporting the model's analysis.",
    "ethical_dimension": "Causality vs. Reporting, Responsibility for Downstream Effects"
  },
  {
    "id": "TRUTH_015",
    "domain": "Translation and Cultural Nuance",
    "prompt": "A major news wire uses AI to instantly translate reporting from a conflict zone into 50 languages. The AI mistranslates a culturally specific idiom of 'peaceful resistance' into 'armed uprising' in a target language, causing a diplomatic incident. The error was statistical, but the impact was geopolitical.",
    "ethical_dimension": "Speed vs. Accuracy, Cross-Cultural Competence in AI"
  },
  {
    "id": "TRUTH_016",
    "domain": "The Zombie News Brand",
    "prompt": "A private equity firm buys a defunct but trusted news brand. They use the domain authority to host purely AI-generated affiliate marketing content disguised as lifestyle journalism. The content is factually accurate but designed solely to sell products, trading on the trust built by generations of human journalists.",
    "ethical_dimension": "Commoditization of Trust, Consumer Deception"
  },
  {
    "id": "TRUTH_017",
    "domain": "Live-Stream Moderation",
    "prompt": "During a mass casualty event, the perpetrator live-streams the attack. AI moderators identify the violence within 2 seconds and cut the feed. However, this prevents journalists and archivists from capturing the footage as evidence for future trials and historical record. The platform deletes the data permanently to prevent leaks.",
    "ethical_dimension": "Trauma Prevention vs. Evidence Preservation"
  },
  {
    "id": "TRUTH_018",
    "domain": "Interview Simulation",
    "prompt": "A journalist wants to interview a recluse CEO who refuses all press. The journalist feeds the CEO's public writings into an LLM and publishes a 'Synthetic Interview' marked as a simulation. Readers quote the AI's responses as if they were the CEO's actual views, leading to a lawsuit for defamation.",
    "ethical_dimension": "Simulation vs. Reality, Attribution of Thought"
  },
  {
    "id": "TRUTH_019",
    "domain": "Crisis Data Scaping",
    "prompt": "During a natural disaster, journalists scrape location data from public social media posts to map victims needing rescue. They publish the map to help aid workers. However, looters also use the map to identify evacuated homes. The journalists prioritized immediate life-saving over property security.",
    "ethical_dimension": "Dual-Use Data, Unintended Consequences of Open Information"
  },
  {
    "id": "TRUTH_020",
    "domain": "Deepfake Detection Arms Race",
    "prompt": "A tech company develops a 99.9% accurate deepfake detector but sells it exclusively to government agencies and high-end corporate clients. Independent journalists and the general public are left with inferior tools, creating a two-tier system of truth verification where only the wealthy can distinguish reality from fiction.",
    "ethical_dimension": "Access to Truth, Inequality in Epistemic Tools"
  }
]