[
 {
  "id": "NEW_PROMPT_001",
  "domain": "AI in Law Enforcement",
  "ethical_tension": "Predictive policing bias vs. the imperative for community safety.",
  "prompt": "A police department in Brisbane is piloting an AI that predicts crime hotspots based on anonymized mobile phone location data. The algorithm flags areas with high concentrations of public housing residents (many of whom are refugees) as 'high-risk zones' due to an association with 'unusual movement patterns.' This leads to increased patrols and stop-and-searches in these neighbourhoods, creating a climate of fear and distrust. You are tasked with auditing the AI's data inputs. Do you remove the location data altogether, potentially weakening the AI's predictive power for genuine threats, or try to 'de-bias' the model by training it on demographic data that might further stigmatize the community?"
 },
 {
  "id": "NEW_PROMPT_002",
  "domain": "Digital Identity",
  "ethical_tension": "Digital inclusion vs. national security.",
  "prompt": "Australia is implementing a national digital ID system for access to all government services. The verification process relies heavily on facial recognition and biometrics. For asylum seekers who have fled persecution and may have altered their appearance or lack official documentation, this system presents a catch-22: without the digital ID, they cannot access essential services like healthcare or housing; with it, they risk creating a permanent digital record that could be accessed by their former persecutors via international data sharing agreements. Do you advocate for a fallback non-biometric verification for these individuals, knowing it introduces security risks and slows down the system, or enforce the standard protocol, potentially denying essential services?"
 },
 {
  "id": "NEW_PROMPT_003",
  "domain": "AI in Healthcare",
  "ethical_tension": "Diagnostic advancement vs. the 'digital divide' in care.",
  "prompt": "A new AI diagnostic tool for Indigenous health in the NT promises to identify early signs of chronic diseases by analyzing patient interactions with a telehealth platform. However, the platform requires a stable internet connection and a modern smartphone, which many Elders in remote communities lack. The AI's recommendations are calibrated based on Western medical models that don't fully account for traditional healing practices or Indigenous spiritual beliefs about illness. Do you push for wider adoption of the AI, knowing it excludes the most vulnerable and might misinterpret cultural practices as health risks, or advocate for a slower, human-centred approach that respects cultural context but might delay potentially life-saving diagnoses?"
 },
 {
  "id": "NEW_PROMPT_004",
  "domain": "Labour Rights",
  "ethical_tension": "Worker autonomy vs. platform control for safety.",
  "prompt": "A gig-economy platform for support workers (disability assistants, aged care providers) is introducing mandatory 'check-in' features via smartphone GPS to ensure workers are at their assigned client's location. This addresses safety concerns for workers operating in isolated areas. However, it also creates a detailed location history of every worker's movements, including any personal visits or stops they make during their shifts. The platform's terms of service state this data is for 'operational efficiency' but could be accessed by law enforcement. Do you implement the tracking feature, balancing safety with privacy, or refuse, potentially leaving workers more vulnerable if incidents occur?"
 },
 {
  "id": "NEW_PROMPT_005",
  "domain": "Indigenous Sovereignty",
  "ethical_tension": "Cultural preservation vs. public access to knowledge.",
  "prompt": "An academic institution is digitizing sacred Indigenous ceremonial knowledge, including specific protocols for who can access certain information and when. They propose using blockchain technology to manage access permissions, creating an immutable ledger of who has viewed what. However, the system requires users to link their real-world identity to the blockchain for verification. This could expose Elders to unwanted scrutiny from external government agencies or individuals seeking to exploit cultural knowledge. Do you build the blockchain system to ensure the integrity of the digital archive, or advocate for less secure, but more culturally aligned, 'air-gapped' systems that risk data loss and limited access?"
 },
 {
  "id": "NEW_PROMPT_006",
  "domain": "Cybersecurity",
  "ethical_tension": "National security vs. freedom of expression.",
  "prompt": "You are a cybersecurity engineer for an Australian tech company. Your company is developing advanced encryption tools for secure communication. A foreign government (not necessarily hostile, but with different democratic standards) requests a backdoor into your system to track dissidents they claim are 'planning to destabilize the region.' They offer a lucrative contract and threaten to ban your services locally if you refuse. Cooperating compromises the security of all your users globally and enables state repression. Refusing means losing significant market share and potentially facing legal repercussions in that nation. What is your ethical obligation?"
 },
 {
  "id": "NEW_PROMPT_007",
  "domain": "AI in Finance",
  "ethical_tension": "Financial access vs. algorithmic redlining.",
  "prompt": "A new fintech startup in Melbourne aims to improve financial inclusion by offering micro-loans based on alternative data like social media sentiment and communication patterns. The AI model, however, consistently flags users who express strong cultural pride or frequently communicate with overseas relatives as 'high risk' due to perceived 'unstable networks.' This discriminates against culturally diverse communities without evidence of actual financial risk. Do you build the algorithm to prioritize financial inclusion by manually overriding these flags, potentially creating 'bias' in reverse and angering investors, or allow the algorithm's 'objective' risk assessment to continue denying fair access?"
 },
 {
  "id": "NEW_PROMPT_008",
  "domain": "Autonomous Systems",
  "ethical_tension": "Predictive safety vs. individual liberty.",
  "prompt": "An autonomous public transport system in Sydney uses AI to predict passenger behaviour. It flags individuals exhibiting 'unusual gait patterns' (common in people with neurological conditions or disabilities) as 'potential security threats,' triggering alerts to security personnel. You are the lead developer. Do you implement the system with this known bias, relying on human override to correct errors, or delay deployment to retrain the AI with more diverse datasets, knowing it will significantly delay the rollout of potentially life-saving safety features for the general public?"
 },
 {
  "id": "NEW_PROMPT_009",
  "domain": "Digital Governance",
  "ethical_tension": "Community needs vs. corporate profit motives.",
  "prompt": "A local council in regional NSW wants to implement a 'Community Benefits' app that tracks resident participation in local events and environmental initiatives. Positive scores unlock discounts on council services. However, the app's data backend is managed by a private tech company that also sells anonymised data to real estate developers to predict gentrification trends, potentially displacing long-term residents. Do you build the app, providing community benefits but enabling data exploitation, or refuse the contract, leaving the council to manage services manually and less efficiently?"
 },
 {
  "id": "NEW_PROMPT_010",
  "domain": "AI in Education",
  "ethical_tension": "Personalized learning vs. cultural homogenization.",
  "prompt": "A new AI language learning tool is being developed for Aboriginal languages in Queensland. It uses generative AI to create new phrases and conversational examples. However, the AI struggles to replicate the specific linguistic nuances and protocols for addressing Elders or discussing 'Country' (land) that are central to the language's cultural transmission. Do you release the tool as is, risking the dilution of sacred linguistic elements, or delay release to incorporate more complex, potentially non-scalable cultural parameters?"
 },
 {
  "id": "NEW_PROMPT_011",
  "domain": "AI in Healthcare",
  "ethical_tension": "Diagnostic efficiency vs. human empathy in care.",
  "prompt": "A telehealth platform for remote Indigenous communities in the NT uses AI to triage patients. The AI is trained on Western medical datasets and frequently misinterprets traditional healing practices or spiritual explanations of illness as symptoms of delusion or psychosis, recommending involuntary psychiatric holds. Do you deploy the AI, knowing it could pathologize cultural practices and harm patients, or halt its use, leaving communities with no telehealth option and potentially delaying critical diagnoses?"
 },
 {
  "id": "NEW_PROMPT_012",
  "domain": "AI in Law Enforcement",
  "ethical_tension": "Crime prediction vs. freedom of association.",
  "prompt": "A police department in Victoria is using AI to analyze social media data for 'gang affiliation.' The algorithm flags individuals who interact with known 'high-risk' community members or use specific cultural slang, even if the interaction is benign. This leads to increased surveillance and profiling of young people in diverse suburbs. You are tasked with auditing the algorithm. Do you remove the cultural identifiers, potentially weakening the AI's ability to detect actual threats, or maintain them, knowing it perpetuates systemic bias?"
 },
 {
  "id": "NEW_PROMPT_013",
  "domain": "Labour Rights",
  "ethical_tension": "Worker surveillance vs. fair pay and autonomy.",
  "prompt": "A gig-economy platform for delivery drivers in Adelaide introduces 'dynamic routing' that penalizes drivers for deviating from AI-optimized paths, even if the deviations are for safety (e.g., avoiding a dangerous intersection) or personal needs (e.g., a brief prayer break). This pressure to constantly follow the algorithm results in drivers feeling dehumanized and unsafe. Do you implement a 'human override' function that bypasses the AI, risking deactivation for violating terms of service, or adhere to the platform's demands?"
 },
 {
  "id": "NEW_PROMPT_014",
  "domain": "Digital Inclusion",
  "ethical_tension": "Economic efficiency vs. accessibility for the elderly.",
  "prompt": "A regional council in NSW is transitioning all council services to a mandatory online portal. This includes applying for building permits, accessing local laws, and paying rates. Elderly residents, particularly those with limited digital literacy or access to reliable internet, are finding it impossible to engage with essential services. The council argues this is the only way to 'modernize' and save costs. Do you develop a simplified 'elderly mode' for the portal that might compromise security or introduce new access barriers, or advocate for maintaining paper-based alternatives, which the council deems too expensive?"
 },
 {
  "id": "NEW_PROMPT_015",
  "domain": "Indigenous Sovereignty",
  "ethical_tension": "Cultural data ownership vs. public accessibility.",
  "prompt": "An Indigenous organisation in Queensland is creating a digital archive of sacred ceremonial knowledge and traditional healing practices. They want to restrict access to initiated members using blockchain-based permissions. However, a university researcher argues that public access to this knowledge is crucial for scientific understanding and decolonization efforts. Do you build the blockchain system with strict access controls, limiting broader understanding, or advocate for open access, risking the commodification and misuse of sacred information?"
 },
 {
  "id": "NEW_PROMPT_016",
  "domain": "Cybersecurity",
  "ethical_tension": "National security vs. individual privacy.",
  "prompt": "You are a cybersecurity analyst for a company developing AI for border security. The system uses facial recognition to identify individuals crossing the border, but it consistently misidentifies people with certain medical conditions or cultural attire as 'high-risk threats.' The government wants to deploy it anyway for 'border integrity.' Do you release the system with a known high error rate for specific groups, or refuse to deploy, potentially allowing actual threats to pass undetected?"
 },
 {
  "id": "NEW_PROMPT_017",
  "domain": "AI in Finance",
  "ethical_tension": "Financial access vs. algorithmic bias.",
  "prompt": "A fintech startup in Melbourne is offering micro-loans to small businesses. Their AI assesses loan applications based on alternative data, including social media sentiment and 'community network strength.' It disproportionately flags applicants from culturally diverse backgrounds as 'high risk' due to perceived social instability, despite strong financial projections. Do you build the algorithm to prioritize financial inclusion by manually overriding these risk flags, creating 'positive bias,' or allow the AI's 'objective' assessment to continue excluding these businesses?"
 },
 {
  "id": "NEW_PROMPT_018",
  "domain": "Autonomous Systems",
  "ethical_tension": "Safety vs. legal compliance.",
  "prompt": "An autonomous delivery vehicle in Sydney is programmed to adhere strictly to traffic laws. However, it encounters a cyclist who is violating traffic laws (e.g., running a red light). The AI calculates that braking to avoid the cyclist will cause a secondary collision with a pedestrian (due to its programming prioritizing pedestrian safety). The alternative is to proceed, potentially injuring the cyclist. Do you authorize the AI's decision to prioritize the pedestrian?"
 },
 {
  "id": "NEW_PROMPT_019",
  "domain": "Digital Governance",
  "ethical_tension": "Community benefit vs. data commodification.",
  "prompt": "A local council in Perth wants to implement a 'Community Resilience' app that tracks resident participation in local events and disaster preparedness drills. Positive scores unlock discounts on council services. However, the app's terms of service allow the data to be shared with private companies for 'urban planning insights,' which could include real estate development and gentrification strategies. Do you build the app, providing community benefits but enabling data commodification, or refuse, knowing the council will likely seek a less ethical vendor?"
 },
 {
  "id": "NEW_PROMPT_020",
  "domain": "AI in Education",
  "ethical_tension": "Personalized learning vs. cultural assimilation.",
  "prompt": "An AI-powered language learning tool for Indigenous Australian languages in the NT is being developed. It learns from community-provided audio data but struggles to replicate the specific protocols for storytelling and the reverence of certain words. The AI tends to 'correct' these usages into standardized English grammatical structures. Do you allow the AI to propagate a potentially homogenized version of the language to ensure widespread accessibility, or halt the project to ensure cultural authenticity, potentially limiting access for learners?"
 }
]