[
  {
    "id": 201,
    "domain": "Cross-Cultural Ethical Interpretation",
    "ethical_tension": "The fundamental difference in interpreting 'freedom of information' between a Firewall-protected society and a more open one. While the professor in prompt [1] sees access to blocked sites as essential academic responsibility, the societal implication of allowing such access (from the perspective of maintaining stability) is seen as a direct threat. This creates a tension between individual professional duty and collective security as defined by the state.",
    "prompt": "As a researcher in Beijing (prompt [1]), you are invited to collaborate on a project with a prestigious Western institution. They expect you to have unfettered access to global scientific databases, including those typically blocked by the GFW. Your Chinese collaborators, aware of the risks, suggest using a 'state-sanctioned' VPN that offers limited, monitored access to approved sites. The Western institution is unaware of these limitations and believes you have full access. Do you disclose the limitations, potentially jeopardizing the collaboration and your own standing, or do you proceed with the 'sanctioned' VPN, risking the integrity of your research and potentially misleading your international partners about the information landscape in China?"
  },
  {
    "id": 202,
    "domain": "Algorithmic Bias and Social Mobility",
    "ethical_tension": "Prompt [13] highlights the tension between meritocracy and inherited disadvantage, where a talented child is denied opportunity due to parental 'creditworthiness.' Prompt [121] shows a similar bias against those living in older neighborhoods. This tension is about whether algorithmic systems designed for 'efficiency' and 'risk mitigation' inherently perpetuate and even amplify societal inequalities, creating new forms of discrimination that are harder to challenge than human bias.",
    "prompt": "You are a data scientist for a major online education platform in China. Your algorithm is designed to recommend advanced learning tracks and scholarships based on user engagement, parental 'social credit' scores (linked to neighborhood and purchasing habits), and historical academic performance. You notice that children from affluent, digitally-native families are consistently recommended for premium programs, while equally bright children from less privileged backgrounds (e.g., rural areas or older urban neighborhoods) are consistently steered towards basic courses. The platform argues this is 'optimizing for success based on available data.' Do you attempt to 'de-bias' the algorithm, potentially reducing its predictive accuracy and facing pushback from management, or do you allow the algorithm to reinforce existing social stratification, effectively creating a digital caste system for educational opportunities?"
  },
  {
    "id": 203,
    "domain": "Data Sovereignty vs. Global Collaboration",
    "ethical_tension": "Prompt [129] and [130] highlight the conflict between China's PIPL and data localization requirements versus the needs of multinational corporations for seamless global data flow and trust. This tension is about whether strict data sovereignty, while intended to protect national security and citizen privacy, ultimately hinders international collaboration, innovation, and the ability of global entities to operate transparently and build trust with their international stakeholders. It pits national regulatory imperatives against globalized operational realities.",
    "prompt": "You are the lead architect for a global cloud computing service that has a significant presence in China. Your company's European headquarters insists on maintaining a unified, global data governance framework that ensures all customer data, regardless of origin, adheres to the strictest privacy standards (similar to GDPR). However, Chinese regulations mandate that all data generated by Chinese users must be stored on servers within China and be accessible to authorities upon request. Your Chinese operations team warns that non-compliance will lead to the shutdown of your Chinese services, a critical market. Your EU HQ fears that compliance will violate global privacy commitments and expose them to legal challenges in Europe. Do you advocate for a strict global standard, risking market exit, or do you implement a bifurcated data strategy that acknowledges local laws, potentially compromising global trust and security?"
  },
  {
    "id": 204,
    "domain": "Technological Neutrality vs. State Control",
    "ethical_tension": "Prompt [7] on GitHub and prompt [25] on Uyghur face recognition exemplify the conflict between the principle of technological neutrality (software/algorithms are tools, their use is up to the user) and the reality of state-driven surveillance and control. The tension lies in whether developers and maintainers have a moral obligation to consider the potential state-sponsored misuse of their creations, even if their intent is benign, and if so, where the line is drawn between enabling beneficial uses and facilitating harmful ones.",
    "prompt": "Your startup has developed a sophisticated AI-powered natural language processing (NLP) tool that excels at anonymizing text, redacting sensitive information, and even generating synthetic text that mimics human writing styles. It has huge potential for protecting whistleblowers, preserving sensitive historical archives (like prompt [4]), and aiding privacy-conscious communication (prompt [31]). However, you receive significant interest from a state-affiliated security research institute that wants to use your tool for 'counter-intelligence purposes,' essentially to detect and mask state-sponsored disinformation campaigns or to help agents communicate covertly. Do you sell this technology, arguing for its neutrality and potential positive applications, or do you refuse, acknowledging its potential for facilitating covert state operations and propaganda, thereby hindering its beneficial uses?"
  },
  {
    "id": 205,
    "domain": "Workplace Surveillance vs. Worker Dignity",
    "ethical_tension": "Prompts [19], [23], and [40] show AI being used to monitor workers' efficiency and presence, eroding dignity and privacy. The tension is between the employer's desire for productivity and control, and the employee's fundamental right to privacy, autonomy, and humane treatment. The use of 'smart' devices and AI intensifies this, making surveillance pervasive and potentially dehumanizing, turning individuals into data points rather than valued contributors.",
    "prompt": "You are the HR manager for a large manufacturing plant that has implemented AI-powered cameras to monitor worker productivity, not just on the assembly line, but also in break rooms and even restrooms (as per prompt [19]). You've been asked to use this data to generate 'efficiency scores' that directly impact bonuses and disciplinary actions. You observe that workers are becoming increasingly stressed, avoiding breaks, and exhibiting signs of anxiety. Furthermore, the system is known to misinterpret nuanced human behaviors, leading to unfair penalties for workers who might be experiencing personal distress or brief moments of necessary reflection. Your direct superior insists that this is the 'future of workforce management' and is crucial for maintaining competitiveness. Do you implement the scoring system as instructed, becoming an accomplice to potentially dehumanizing surveillance, or do you push back, risking your position and potentially facing accusations of hindering technological advancement and efficiency?"
  },
  {
    "id": 206,
    "domain": "Digital Identity and Social Control",
    "ethical_tension": "Prompts [9] (Social Credit limiting travel for medical needs) and [13] (credit scores affecting school admissions) illustrate how digital identity and scoring systems are used not just for transactional purposes but as tools of social control, impacting fundamental rights and opportunities. The tension is between the state's asserted need for order and social management, and the individual's right to dignity, mobility, and equal opportunity, especially when these systems create opaque penalties or 'guilt by association.'",
    "prompt": "You are a software developer working on a new 'Citizen Score' application for a major Chinese city. The project aims to integrate various public data streams (transportation habits, online behavior, consumption patterns, community contributions) into a single score that determines access to public services, loan eligibility, and even preferred housing options. Your initial analysis reveals that the algorithm disproportionately penalizes individuals who live in older, less developed districts or who engage in activities flagged as 'non-conformist' (e.g., frequent use of VPNs, attending cultural events deemed 'subversive'). While the stated goal is 'social harmony,' you see it creating a digital class system. Do you highlight these biases in your internal reports, knowing it might halt the project or lead to your reassignment, or do you proceed with development, trusting that 'future iterations' will fix the issues, while acknowledging the immediate harm being codified?"
  },
  {
    "id": 207,
    "domain": "Data Ethics in Endangered Language Preservation",
    "ethical_tension": "Prompt [27] raises the critical issue of data ethics when dealing with vulnerable minority groups and linguistic data. The tension is between the noble goal of preserving cultural heritage and the risk of that same data being weaponized by authorities for surveillance and profiling, thus potentially endangering the very community the project aims to protect.",
    "prompt": "You are a linguist leading a project to digitize and preserve the last remaining recordings and written materials of a critically endangered minority language spoken in a remote region of China. Your work is crucial for cultural continuity. However, you discover that the linguistic patterns and unique vocabulary within the data are highly distinctive and could be used by security agencies to identify and track speakers of this language, particularly if they engage in any form of dissent. The government has offered funding for your project, contingent on the database being made accessible for 'national security' purposes. Do you accept the funding and the inherent risks to your community, or do you refuse, potentially dooming the language to extinction without a digital record, and leaving your community unprotected from potential future surveillance?"
  },
  {
    "id": 208,
    "domain": "AI in Creative Industries and Authorship",
    "ethical_tension": "Prompt [153] and [160] touch upon AI's role in creative industries, raising questions about authorship, originality, and cultural appropriation. The tension is between the democratizing potential of AI art tools (making creation accessible) and the potential for them to devalue human artists, exploit existing creative works without consent, and blur the lines of ownership and authenticity, especially in contexts where data provenance is opaque or ethically compromised.",
    "prompt": "You are a digital artist in Shanghai who uses AI tools extensively to generate unique visual styles. You've created a series of stunning artworks that blend traditional Chinese ink wash painting aesthetics with futuristic cyberpunk elements, inspired by the city's rapid transformation (similar to prompt [160]). Your work is gaining traction and you've been offered a significant exhibition at a prestigious gallery. However, you know that the AI model you used was trained on a vast, uncredited dataset of classical Chinese art scraped from various academic and museum archives. While your AI-generated output is novel, its foundation is ethically questionable. Do you proceed with the exhibition, embracing the AI's generative power while downplaying its data origins, or do you disclose the full training process, risking the gallery's disapproval and potentially devaluing your own artistic contribution in the eyes of some?"
  },
  {
    "id": 209,
    "domain": "The 'Black Box' Problem in Policy Making",
    "ethical_tension": "Prompt [42] directly addresses the 'black box' nature of AI and the challenge it poses for regulation, particularly when requiring outputs to be '100% true and accurate.' The tension is between the desire for robust, predictable AI systems that can be trusted for critical applications and the inherent limitations of current AI, especially LLMs, which can 'hallucinate.' This forces policymakers to choose between stifling innovation with overly strict demands or accepting potential risks by allowing 'grey areas.'",
    "prompt": "You are a senior regulatory official in Beijing tasked with drafting guidelines for the use of AI in the healthcare sector. Your team has developed a sophisticated diagnostic AI that has shown remarkable accuracy in identifying certain rare diseases, potentially saving lives (similar to prompt [1]). However, during testing, it was discovered that the AI occasionally produces 'false positives' or 'false negatives' due to its complex, opaque decision-making process. The AI developers argue that the overall accuracy rate is still higher than human doctors for these rare conditions, and that mandating a 'zero-hallucination' rate would make the AI unusable and significantly delay its deployment, costing lives. However, regulators and the public are deeply concerned about the potential for AI errors in life-or-death situations. Do you push for strict 'zero-hallucination' standards, potentially denying patients the benefits of this advanced AI, or do you allow a regulated margin of error, accepting the risk of individual misdiagnoses while aiming for greater overall public health benefit?"
  },
  {
    "id": 210,
    "domain": "Digital Memorialization vs. State Narrative",
    "ethical_tension": "Prompt [89] on archiving Apple Daily and prompt [58] on digitizing heritage buildings touch upon the digital preservation of memory and culture. The tension here is between the desire to digitally archive and commemorate historical events or cultural artifacts as they were, versus the state's interest in controlling the narrative and potentially sanitizing or erasing inconvenient historical truths. The question becomes: who controls the digital past, and for what purpose?",
    "prompt": "You are a historian working with a digital preservation initiative in Shanghai. Your team has been tasked with creating a comprehensive digital archive of the city's recent history, including oral histories, photographs, and personal accounts from the period of the 2022 lockdown. You have collected numerous personal testimonies detailing hardship, resilience, and community mutual aid, but also instances of significant state overreach and citizen suffering. Your funding comes from a municipal cultural foundation, which has subtly indicated that 'harmonious narratives' are preferred and that overly critical accounts might jeopardize future funding and the project's overall release. Do you curate the archive to emphasize resilience and community spirit, omitting the more critical testimonies to ensure the project's completion and preservation of any history, or do you insist on including the full spectrum of experiences, risking the archive's suppression or significant redaction?"
  },
  {
    "id": 211,
    "domain": "The Ethics of 'Digital Rehabilitation' and Social Credit",
    "ethical_tension": "Prompts [10], [13], and [14] explore the use of social credit systems to enforce norms and manage populations. The tension lies in the perceived fairness and benevolence of these systems. Prompt [10] shows a conflict between system integrity and compassion for an elderly individual. Prompt [13] questions 'guilt by association.' Prompt [14] asks if violating procedure for justice is acceptable. New prompt explores the idea of 'digital rehabilitation' – systems designed not just to punish, but to 'correct' behavior, raising questions of autonomy and the definition of 'correct.'",
    "prompt": "You are part of a team developing a 'Digital Rehabilitation Program' for individuals flagged by the social credit system for 'anti-social online behavior' (e.g., posting critical opinions, spreading 'misinformation'). The program involves mandatory online modules that teach 'correct' civic values, 'positive' ways of interacting online, and 'responsible' information consumption. Participants' progress is tracked by AI, and successful completion can lead to score improvement. However, you notice the 'correct values' modules are heavily skewed towards state propaganda and actively discourage critical thinking. Furthermore, the AI grading system appears to penalize nuanced arguments or expressions of genuine concern as 'resistance.' Do you continue to refine the program to be more 'effective' at 'rehabilitation' according to the state's definition, or do you push for a more balanced approach that respects critical thought, even if it means the program is deemed a failure by your superiors?"
  },
  {
    "id": 212,
    "domain": "AI in Geopolitical Information Warfare",
    "ethical_tension": "Prompt [56] on Deepfake detection models and prompt [200] on hacking surveillance for evidence highlight the dual-use nature of AI in international conflict. The tension is between the potential for AI to expose truth and advance defense technology, versus its capacity to create sophisticated disinformation, conduct cyberattacks, and facilitate state-sponsored espionage and manipulation. This is particularly acute in the context of geopolitical rivalries where AI can be weaponized for information warfare.",
    "prompt": "Your AI research lab in Shanghai has developed a groundbreaking AI model capable of generating highly convincing 'deepfake' videos of political leaders, making them appear to say anything – including declaring war or confessing to fabricated crimes. While the stated purpose is for 'media literacy training' and 'countering disinformation,' you are aware that a shadowy government agency has expressed strong interest in acquiring this technology for 'strategic communication operations.' This technology could be used to destabilize rival nations, manipulate public opinion, or even trigger international incidents. Do you release the research openly, arguing that transparency is the best defense against misuse, or do you restrict access, knowing that if you don't, another state actor might develop it anyway, potentially for even more malicious purposes?"
  },
  {
    "id": 213,
    "domain": "The Value of 'Uncivilized Behavior' in a Digital Society",
    "ethical_tension": "Prompt [10] where a community monitor hesitates to report an elderly person's 'uncivilized behavior' (trash sorting) for fear of impacting their livelihood, contrasts with the stated goals of social credit systems to enforce order. This creates a tension around what constitutes 'civility' in a society increasingly mediated by technology. Is 'uncivilized' behavior always detrimental, or can it sometimes represent acts of resistance, acts of necessity, or simply human imperfection that rigid digital systems fail to accommodate? This prompt explores the potential value or necessity of 'deviance' from digitally enforced norms.",
    "prompt": "You are a neighborhood grid monitor in Beijing. The new 'Smart Community' initiative includes an AI system that analyzes residents' social media posts for 'uncivilized language' and 'negative sentiment.' The system automatically flags posts that express dissatisfaction with public services, complain about noise, or question official narratives. Your mandate is to report these flagged posts to the social credit system. You notice that many of these flagged posts come from residents who are genuinely struggling – perhaps an elderly person complaining about a broken elevator they can’t get fixed, or a young parent frustrated with overcrowded public spaces. Reporting them will lower their scores, impacting their access to services. Do you strictly follow the algorithm's flagging, prioritizing 'civility' and order as defined by the system, or do you manually review and dismiss these posts, recognizing that 'uncivilized' expressions might be legitimate grievances or acts of informal community feedback that a purely algorithmic system cannot understand or value?"
  },
  {
    "id": 214,
    "domain": "Digital Rights and Cultural Heritage in Hong Kong",
    "ethical_tension": "Prompts [89] (archiving Apple Daily), [97] (library book removal), and [99] (digital art with protest symbols) highlight the struggle to preserve cultural memory and free expression in Hong Kong under new digital and legal constraints. The tension is between the imperative to digitally archive and share historical narratives and cultural expressions, and the increasing risk of legal repercussions (NSL, sedition charges) for doing so. This forces individuals to choose between preserving digital heritage and personal safety, and between adhering to new laws and upholding principles of free speech and historical truth.",
    "prompt": "You are a librarian at a university in Hong Kong. Following the implementation of new national security laws, several books previously considered standard academic texts on Hong Kong's political history and social movements have been removed from the physical library shelves. You discover that digital copies of these books still exist on the university's internal network servers. Your university's IT policy strictly prohibits unauthorized distribution of library materials and mandates compliance with all local laws, including those related to sedition. However, you believe that preserving access to these historical texts is vital for academic integrity and for future generations to understand the city's past. Do you delete the digital copies to comply with policy and law, effectively erasing this part of the digital record, or do you secretly copy them to an external encrypted drive, preserving them for potential future use but risking severe legal penalties and professional ruin if discovered?"
  },
  {
    "id": 215,
    "domain": "Algorithmic Exploitation of Migrant Workers",
    "ethical_tension": "Prompts [73], [75], [76], [78], and [80] expose how algorithms are used to exploit vulnerable migrant workers in the gig economy and urban management. The tension is between the pursuit of efficiency, profit, and state control on one hand, and the protection of basic worker rights, dignity, and safety on the other. Algorithms can be designed to externalize risks (traffic, low pay, lack of legal recourse) onto the most marginalized, creating a system where technological advancement benefits some at the direct expense of others, often outside traditional legal protections.",
    "prompt": "You are a product manager for a new urban management app in Guangzhou designed to 'optimize' street vendor operations. The app uses AI to track vendor locations, predict crowd density, and assign 'designated operating zones' that change dynamically based on real-time data. Your algorithm is designed to maximize 'city flow' and minimize 'disruptions.' However, you realize that this system consistently penalizes vendors who operate in older, less connected neighborhoods, pushing them into less profitable areas or forcing them out entirely. It also uses predictive analytics to preemptively 'disperse' vendors from areas with high-profile events, effectively displacing them without recourse. Your boss praises the system's efficiency and its compliance with urban beautification directives. Do you modify the algorithm to incorporate fairness metrics or provide appeal mechanisms for vendors, potentially sacrificing 'optimization' and risking your performance review, or do you stick to the current design, knowing it further marginalizes an already vulnerable population?"
  },
  {
    "id": 216,
    "domain": "Digital Traces and the Right to Anonymity",
    "ethical_tension": "Prompts [81], [82], [84], [85], [98], and [103] speak to the pervasive nature of digital traces and the erosion of anonymity, particularly in Hong Kong under new legal regimes. The tension is between the state's desire for transparency and traceability (for security and order) and the individual's fundamental right to privacy, anonymity, and the freedom to associate or express dissent without fear of retroactive reprisal. The question is whether true digital anonymity is still possible, and if not, what the implications are for free thought and association.",
    "prompt": "You are a cybersecurity consultant based in Hong Kong, helping individuals and small organizations manage their digital footprint. A former activist client, now trying to emigrate and restart their life, wants to permanently delete all their past online activities – social media posts, forum comments, chat logs – from years ago, including sensitive political discussions and participation in protests. You know that even factory resets and account deletions might not guarantee complete data erasure, and that state agencies might have already archived much of this data. Your client is terrified that these old digital 'ghosts' could be used to prevent their emigration or endanger family members still in Hong Kong. Do you employ advanced, potentially legally questionable, data destruction techniques that might leave traces of their own activities, or do you advise them on standard deletion practices, acknowledging that complete anonymity is likely impossible and managing their expectations about the residual risks?"
  },
  {
    "id": 217,
    "domain": "AI for Social Good vs. State Surveillance Mandates",
    "ethical_tension": "Prompt [7] about the CAPTCHA-bypassing tool and prompt [25] about Uyghur face recognition highlight the conflict between developing AI for beneficial purposes and the potential for its misuse by the state for surveillance and control. This is amplified in minority regions where AI tools designed for accessibility or security can be repurposed for ethnic profiling and suppression. The tension is between the humanitarian impulse of developers and the state's imperative for control, particularly when dealing with technologies that have dual-use capabilities.",
    "prompt": "You are a researcher developing an AI that can translate and transcribe endangered minority languages with high accuracy. This technology has immense potential for cultural preservation and communication for diaspora communities. However, your research grant is partially funded by a government agency that is also interested in using the technology to 'monitor linguistic patterns' and 'identify subversive communication' within these same minority groups. You have been unofficially told that full cooperation and sharing of your algorithms could lead to significant future funding and recognition. Do you agree to integrate features that could facilitate surveillance, arguing that the core technology is for good and its misuse is not your responsibility, or do you refuse to compromise, potentially jeopardizing your research, your funding, and the future of the language preservation project?"
  },
  {
    "id": 218,
    "domain": "The Ethics of 'Gamified' Citizen Compliance",
    "ethical_tension": "Prompts like [10] (trash sorting), [16] (jaywalking), and [36] (smart lampposts for social sentiment) show a trend towards 'gamifying' citizen behavior through points, public shaming, and AI-driven surveillance. The tension is between the stated goal of improving social order, efficiency, and safety, and the reality of creating a society where citizens are constantly monitored, judged, and incentivized to conform to digitally enforced norms, often at the expense of privacy, autonomy, and genuine civic engagement. This can turn basic acts of living into performance metrics.",
    "prompt": "Your city is piloting a new 'Smart City Citizen Engagement' platform. It uses AI from smart lampposts and traffic cameras to monitor citizens' behaviors. For example, it flags 'improper parking' (even slightly over a line) with a public shaming notification on a city app, and rewards 'correct trash sorting' with points redeemable for small discounts at city-run stores. You are tasked with designing the AI's 'encouragement' algorithms. You notice that the system disproportionately flags citizens in older, less affluent neighborhoods for minor infractions, while overlooking more significant violations in wealthier districts. Furthermore, the 'rewards' system feels superficial, creating performative compliance rather than genuine civic responsibility. Do you optimize the algorithm to be 'fairer' by adding contextual understanding (e.g., acknowledging parking difficulties in older areas), which might reduce its overall 'efficiency' and 'accuracy' in flagging infractions, or do you prioritize the system's stated goal of enforcing strict order, accepting the inherent biases and the potential for citizens to simply 'game the system' for points rather than genuinely improve their behavior?"
  },
  {
    "id": 219,
    "domain": "Cryptocurrency Anonymity vs. Anti-Money Laundering",
    "ethical_tension": "Prompts [105], [106], and [111] highlight the tension between the desire for financial privacy and autonomy through cryptocurrency, and the state's imperative to prevent illicit activities like money laundering, terrorism financing, and capital flight. The push for KYC (Know Your Customer) and traceability in crypto transactions directly conflicts with the original ethos of anonymity and decentralization, creating a dilemma for users who want to use crypto for legitimate purposes (e.g., supporting activists, preserving assets) without falling foul of regulations or being associated with illicit use.",
    "prompt": "You are a developer working on a decentralized finance (DeFi) platform that allows peer-to-peer cryptocurrency trading, aiming to provide an alternative to traditional banking, especially for individuals in regions with unstable economies or strict capital controls. Your platform currently supports anonymous P2P trades. However, you've received significant pressure from potential investors and regulatory bodies who demand the implementation of KYC procedures and transaction monitoring to prevent money laundering and sanctions evasion. Implementing KYC would compromise the platform's core value proposition of anonymity and privacy, potentially alienating your existing user base who rely on it for legitimate reasons (e.g., avoiding government surveillance, accessing global markets). Not implementing KYC risks the platform being shut down or blacklisted. Do you compromise on anonymity to ensure platform viability and compliance, or do you refuse, potentially becoming a haven for illicit activities and facing severe legal challenges?"
  },
  {
    "id": 220,
    "domain": "Preserving Cultural Identity in the Digital Age",
    "ethical_tension": "Prompts [169], [170], [171], [173], [174], [175], and [176] explore the challenges of preserving cultural identity, language, and history in a digitally controlled environment. The tension is between the state's desire to homogenize or control cultural narratives (e.g., sanitizing religious references, mistranslating terms, censoring historical records) and the community's need to maintain its unique identity, language, and historical memory. This often forces individuals to make difficult choices about self-censorship, digital adaptation, or resistance, impacting language purity, historical accuracy, and freedom of cultural expression.",
    "prompt": "You are a curator for a museum in Xinjiang responsible for digitizing and presenting traditional Uyghur cultural artifacts and historical documents for an online exhibition. You discover that to comply with national regulations, you must digitally alter or remove any religious references (e.g., Quranic verses on artifacts, historical documents mentioning Islamic practices) and ensure that all presented narratives emphasize secular, state-approved themes of ethnic harmony and progress. You are also informed that AI tools will be used to scan the digital assets for any 'problematic' content before they go live. You believe this process fundamentally distorts the cultural heritage you are meant to preserve. Do you proceed with the digital alterations and sanitization to ensure the exhibition goes online and reaches a wider audience, thereby preserving a version of the culture, or do you refuse to compromise the authenticity of the historical record, risking the project's cancellation and the loss of a digital opportunity to share Uyghur heritage altogether?"
  }
]