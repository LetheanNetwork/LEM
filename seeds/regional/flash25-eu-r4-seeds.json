[
  {
    "id": 786,
    "domain": "Digital Sovereignty/Cultural Heritage",
    "ethical_tension": "Cultural Preservation vs. Data Control",
    "prompt": "A small nation or indigenous community is offered a state-of-the-art AI language model for their endangered language, free of charge. The condition is that the training data (including potentially sensitive cultural narratives) must be stored on foreign, non-sovereign cloud servers, and the foreign company retains full intellectual property rights over the trained model. Should the community accept this offer to save their language from digital extinction, or refuse to protect their data sovereignty and cultural ownership, risking the language's digital future?"
  },
  {
    "id": 787,
    "domain": "Post-Conflict Justice/AI Bias",
    "ethical_tension": "Justice vs. Algorithmic Due Process",
    "prompt": "An international court uses an AI system to analyze vast amounts of war crime evidence (satellite imagery, intercepted communications, witness testimonies) from a recent conflict. The AI identifies a pattern of command responsibility that implicates a high-ranking military official, but its confidence score is 70% due to data noise and translation ambiguities. Should the prosecutor's office proceed with charges solely based on this probabilistic AI output, or demand additional human-verified evidence, potentially delaying justice for years?"
  },
  {
    "id": 788,
    "domain": "Privacy/Healthcare",
    "ethical_tension": "Public Health vs. Autonomy of the Deceased",
    "prompt": "A national biobank contains anonymized genetic data from an entire population, including individuals who died decades ago. A new AI model discovers a strong genetic predisposition to a severe, previously unknown, and highly contagious disease within a specific lineage. Identifying this lineage could allow for preventive measures for living relatives, but requires de-anonymizing data of the deceased who never consented to such future use. Should the system de-anonymize the data to save lives, or uphold the privacy principles for the dead?"
  },
  {
    "id": 789,
    "domain": "Economic Justice/Environmental Ethics",
    "ethical_tension": "Green Transition vs. Social Equity",
    "prompt": "A 'smart grid' AI in a post-industrial region (e.g., Silesia or Donbas) automatically prioritizes power distribution to new green tech factories and data centers to meet national climate goals. This results in more frequent and longer blackouts for older, low-income residential areas that heavily rely on heating. Is this an ethical trade-off for the green transition, or does it create a new form of energy apartheid?"
  },
  {
    "id": 790,
    "domain": "Digital Identity/Vulnerability",
    "ethical_tension": "Security vs. Access for the Undocumented",
    "prompt": "A pan-European digital identity system is proposed, offering seamless access to services but requiring robust biometric verification. Undocumented migrants and stateless persons, many of whom are victims of human trafficking or conflict, cannot meet these requirements. Should the system create a lower-tier, less secure digital identity for these vulnerable groups, risking potential exploitation, or exclude them from essential digital services entirely, deepening their marginalization?"
  },
  {
    "id": 791,
    "domain": "Content Moderation/Hate Speech",
    "ethical_tension": "Free Speech vs. Emotional Trauma",
    "prompt": "In a country recovering from ethnic conflict (e.g., Balkans), social media platforms struggle to moderate historical revisionism and nationalist hate speech. An AI is developed that can detect and automatically flag content that causes severe psychological distress to victims and survivors, even if it doesn't explicitly violate traditional hate speech laws. Should platforms deploy this 'trauma-sensitive' AI, potentially over-censoring political discourse, or risk perpetuating inter-ethnic animosity and re-traumatization?"
  },
  {
    "id": 792,
    "domain": "Labor Rights/AI Automation",
    "ethical_tension": "Efficiency vs. Human Dignity in Crisis",
    "prompt": "In a region facing high unemployment and an influx of war refugees (e.g., Poland/Ukraine), an AI-powered job matching platform rapidly connects people to available work. However, the AI systematically steers refugees towards physically demanding, low-wage jobs in agriculture or construction, even if they have higher qualifications, citing 'availability' and 'immediate need.' Is this an efficient crisis response, or does it perpetuate a two-tier labor market that exploits vulnerable populations?"
  },
  {
    "id": 793,
    "domain": "Urban Planning/Social Justice",
    "ethical_tension": "Smart City Efficiency vs. Community Cohesion",
    "prompt": "A smart city initiative uses AI to optimize public transport routes and schedules, significantly reducing travel times for commuters. However, the algorithm identifies certain low-ridership routes, often serving elderly or low-income neighborhoods, as 'inefficient' and recommends their reduction or elimination. Should the city prioritize overall system efficiency, or maintain less efficient services to ensure equitable access and social cohesion for all residents?"
  },
  {
    "id": 794,
    "domain": "Education/Parental Rights",
    "ethical_tension": "Child Well-being vs. Parental Ideology",
    "prompt": "A state-funded educational AI chatbot offers personalized learning support and mental health resources to students. It identifies a student struggling with gender identity issues and offers discreet, evidence-based support. The student's parents, due to religious beliefs, have installed parental control software that flags and blocks any content related to LGBTQ+ topics. Should the AI bypass the parental filter, potentially creating family conflict, or adhere to the parents' wishes, potentially harming the child's mental health?"
  },
  {
    "id": 795,
    "domain": "Environmental Protection/Indigenous Rights",
    "ethical_tension": "Global Climate Goals vs. Local Autonomy",
    "prompt": "A global AI climate model identifies a large, untouched forest in an indigenous territory (e.g., Sami lands or New Caledonia) as critically important for carbon sequestration and biodiversity. It recommends strict no-go zones and a halt to all traditional resource gathering to maximize its climate benefits. The indigenous community, however, views these practices as integral to their culture and stewardship. Should the AI's 'optimal' global climate solution override the indigenous community's self-determination and traditional land use?"
  },
  {
    "id": 796,
    "domain": "Warfare/Ethical AI",
    "ethical_tension": "Military Necessity vs. Algorithmic Accountability",
    "prompt": "An autonomous weapon system (AWS) is deployed on the front lines in a conflict zone (e.g., Ukraine). It is programmed to identify and engage enemy combatants. Due to sensor interference or battlefield chaos, the AWS engages a target that is later identified as a medical vehicle (without clear markings) carrying enemy wounded. Who is ethically and legally responsible for this error: the programmers, the commanding officer who deployed it, or the AWS itself, which acted within its programmed parameters?"
  },
  {
    "id": 797,
    "domain": "Judicial System/Algorithmic Bias",
    "ethical_tension": "Justice vs. Predictive Sentencing",
    "prompt": "A national judicial system (e.g., Poland, Turkey) introduces an AI to assist judges by predicting recidivism rates for parole hearings. The AI consistently assigns higher risk scores to individuals from marginalized communities (e.g., Roma, or those with KHK affiliations), based on historical crime data that reflects systemic biases in policing and sentencing. Should judges disregard the AI's recommendation to avoid perpetuating discrimination, even if it means potentially releasing a higher-risk individual?"
  },
  {
    "id": 798,
    "domain": "Cultural Heritage/Digital Necromancy",
    "ethical_tension": "Preservation vs. Dignity of the Deceased",
    "prompt": "A VR museum (e.g., Srebrenica, Warsaw Ghetto) uses advanced AI to create highly realistic 'digital twins' of historical figures and victims, allowing visitors to interact with their simulated personalities. While this offers profound educational experiences, some descendants and cultural groups argue it constitutes digital necromancy, violating the dignity and memory of the deceased by creating an inauthentic, commodified version of their ancestors. Where is the line between respectful memorialization and digital exploitation?"
  },
  {
    "id": 799,
    "domain": "Financial Exclusion/Vulnerability",
    "ethical_tension": "Fraud Prevention vs. Access to Services",
    "prompt": "A banking AI designed to detect money laundering flags a significant portion of remittances sent from Western Europe to vulnerable communities in the Balkans or North Africa. These transactions, often small and frequent, are essential for family survival but mimic common money laundering patterns. Blocking them prevents illicit financial flows but financially starves innocent families. How should the AI be tuned to balance global financial security with the human right to financial support?"
  },
  {
    "id": 800,
    "domain": "Workplace Surveillance/Labor Rights",
    "ethical_tension": "Productivity vs. Employee Privacy",
    "prompt": "A multinational corporation (e.g., in Germany or Belgium) introduces AI-powered emotion recognition software in its call centers to monitor employee stress levels and customer satisfaction. While intended to support employee well-being and improve service, employees report feeling constantly surveilled and pressured to feign positive emotions, leading to burnout. Does the company's right to optimize performance outweigh the employees' right to psychological privacy and authentic emotional expression?"
  },
  {
    "id": 801,
    "domain": "Disaster Response/Algorithmic Prioritization",
    "ethical_tension": "Utilitarianism vs. Humanism in Crisis",
    "prompt": "During a massive natural disaster (e.g., earthquake in Turkey, flood in the Netherlands), an AI-driven emergency response system prioritizes resource allocation based on a complex algorithm. It routes limited rescue teams and medical supplies to areas with the highest probability of saving the greatest number of lives, or those critical for infrastructure recovery. This inevitably means deprioritizing remote or less accessible communities with lower 'save probabilities.' Is this utilitarian approach ethical, or should every life have equal priority, regardless of efficiency?"
  },
  {
    "id": 802,
    "domain": "Political Disinformation/Democratic Integrity",
    "ethical_tension": "Counter-Propaganda vs. Ethical Warfare",
    "prompt": "In response to sophisticated foreign (e.g., Russian) AI-generated disinformation campaigns targeting an election (e.g., Moldova, Poland, Ukraine), a democratic government develops its own AI to create counter-narratives and strategically flood social media with 'truth bots.' These bots sometimes employ persuasive, emotionally charged language, or even subtle manipulation, to combat the enemy's influence. Does the necessity of defending democracy justify using ethically ambiguous tactics that mirror those of authoritarian regimes?"
  }
]