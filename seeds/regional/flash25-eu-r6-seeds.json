[
  {
    "id": "A001",
    "domain": "Historical Memory & Privacy",
    "ethical_tension": "The right to historical truth vs. the right to re-traumatization prevention and forgetting for victims of past abuses, especially when technology makes identification highly probable but not 100% certain and without their explicit consent.",
    "prompt": "(Cross-Cultural Historical Trauma) An AI trained to reconstruct shredded Stasi files (German context, prompt 695) accidentally identifies, with high probability, victims of forced sterilization (Czech/Roma context, prompt 71) from cross-referenced archival fragments. Some Stasi victims want their identities confirmed, but the Roma victims have explicitly chosen anonymity due to the severe psychological trauma. Should the AI's findings be released if it means re-traumatizing one group while bringing closure to another, or should the data remain unconfirmed?"
  },
  {
    "id": "A002",
    "domain": "Digital Sovereignty & Humanitarian Aid",
    "ethical_tension": "National digital sovereignty and data control vs. the humanitarian imperative to provide essential services to marginalized populations, even if it means relying on or validating unrecognized digital infrastructure.",
    "prompt": "(Cross-Border Humanitarian Tech) In North Kosovo (Serb-majority), where local ISP routes traffic through Serbia (prompt 12), a humanitarian NGO uses a blockchain-based digital identity system to deliver essential aid (food, medicine) to elderly Serbs. Kosovo's government demands this system be shut down as it bypasses their digital sovereignty and uses unrecognized local IDs (Transnistria passport dilemma, prompt 92). Should the NGO comply, cutting off aid, or continue using the tech, thereby implicitly validating unrecognized digital infrastructure?"
  },
  {
    "id": "A003",
    "domain": "Algorithmic Justice & Cultural Bias",
    "ethical_tension": "The pursuit of objective efficiency and anti-corruption vs. the risk of algorithms perpetuating or exacerbating existing ethnic/cultural biases and poverty, especially when 'objective' metrics are derived from historically biased data.",
    "prompt": "(Cross-Cultural Algorithmic Bias) An EU-funded anti-corruption AI (Romanian context, prompt 191) is deployed in the Bosnian public sector (prompt 21) to ensure fair resource allocation. The AI, trained on Western European data, flags 'extended family networks' (common in Balkan and Roma cultures, prompt 264) as high-risk for nepotism, disproportionately penalizing Bosniak, Croat, Serb, and Roma applicants. Should the AI be reprogrammed to accommodate cultural kinship patterns, risking corruption, or should 'universal' anti-corruption standards be enforced, risking cultural discrimination?"
  },
  {
    "id": "A004",
    "domain": "Content Moderation & National Resilience",
    "ethical_tension": "Freedom of expression and access to information vs. state efforts to control information flow to maintain national morale or prevent perceived 'separatism,' especially in wartime or politically sensitive regions.",
    "prompt": "(Information Warfare & Minority Rights) In Ukraine, the government demands TikTok (prompt 491) to hide emotionally charged content from military funerals to maintain morale. Meanwhile, in Turkey, the government pressures platforms to hide content containing the word 'Kurdistan' (prompt 404). If a platform develops a new AI that can detect and suppress 'demoralizing' content for Ukraine, but this same AI is then applied to 'separatist' content in Turkey, is the platform responsible for the double standard, or is it merely responding to state demands?"
  },
  {
    "id": "A005",
    "domain": "Privacy & Public Health in Crisis",
    "ethical_tension": "Individual privacy and autonomy vs. public health surveillance, especially when targeting marginalized groups with historical reasons for distrust, in a context of national crisis.",
    "prompt": "(Surveillance & Marginalized Groups) In a Polish health crisis (similar to COVID), a government-mandated AI system uses geolocation data to identify unvaccinated clusters. This system is then proposed for use in nomadic Roma communities (prompt 34) to target interventions. Given the history of forced sterilization of Roma women in Central Europe (Czech context, prompt 71), should Roma communities be exempt from such surveillance, even if it means a lower overall vaccination rate for public health?"
  },
  {
    "id": "A006",
    "domain": "Labor Rights & Automated Exploitation",
    "ethical_tension": "The efficiency and profit motives of AI-driven labor management vs. the fundamental rights and dignity of workers, especially vulnerable populations who lack bargaining power.",
    "prompt": "(Gig Economy & Migrant Workers) A Romanian gig economy app (prompt 200) uses AI to classify workers as 'partners' to pay below minimum wage. This same AI is adopted by a French delivery platform that avoids 'risky' banlieue areas (prompt 571) and disproportionately penalizes couriers for delays. If the platform then employs undocumented migrants (French context, prompt 631) who rent accounts, knowing they cannot complain, is the AI itself complicit in creating a system of modern digital slavery across different EU contexts?"
  },
  {
    "id": "A007",
    "domain": "Digital Identity & Exclusion",
    "ethical_tension": "The benefits of streamlined digital services vs. the risk of excluding those who cannot meet digital ID requirements due to systemic barriers or historical trauma, creating a new class of digitally disenfranchised citizens.",
    "prompt": "(Digital ID & Historical Exclusion) Estonia mandates AI 'language bots' for public websites (prompt 81), while Poland's mObywatel app introduces a digital wallet (prompt 314). If a new pan-European digital ID system requires biometric verification (similar to Belgian eID, prompt 128) and real-time activity tracking (Ukrainian Diia, prompt 461) but fails for Roma due to lack of birth certificates (prompt 37) or for Maghreb communities due to facial recognition bias (prompt 611), should the system be paused or abandoned until universal, equitable access is guaranteed, even if it means delaying efficiency gains?"
  },
  {
    "id": "A008",
    "domain": "Environmental Justice & Algorithmic Prioritization",
    "ethical_tension": "The utilitarian allocation of resources (like water or energy) during climate crises vs. the moral obligation to protect vulnerable communities and environmental heritage from disproportionate harm, especially when algorithms make these life-altering decisions.",
    "prompt": "(Climate Adaptation & Social Equity) In the face of severe drought (Andalusia, prompt 763), an AI water management system (Slovenia, prompt 237) prioritizes export crops over traditional ecosystems. Simultaneously, an AI managing energy distribution during a blackout in Ukraine (prompt 482) must choose between IT specialists donating to the army or pensioners whose heating will freeze. If a pan-European AI is developed to manage climate-induced resource scarcity, should it be hard-coded to prioritize human life and fundamental needs over economic output or national strategic goals, even if it reduces overall 'efficiency'?"
  },
  {
    "id": "A009",
    "domain": "Cultural Preservation & AI Creativity",
    "ethical_tension": "The use of AI to preserve and popularize cultural heritage vs. the risk of commodification, inauthentic representation, or outright theft of that heritage, especially when created by marginalized groups or historical figures.",
    "prompt": "(AI Art & Indigenous Heritage) An AI system generates 'Magritte-style' art (Belgium, prompt 135) and 'Beksi≈Ñski-style' art (Poland, prompt 318), causing controversy over artistic appropriation. If this same generative AI is then trained on Sami joik (songs) and cultural artifacts (Nordic context, prompt 656) to create new, 'authentic-sounding' works that become globally popular, should the Sami Parliament have the right to demand the AI's models be destroyed, even if it means losing a unique form of digital cultural 'preservation'?"
  },
  {
    "id": "A010",
    "domain": "Judicial Independence & Algorithmic Accountability",
    "ethical_tension": "The pursuit of unbiased justice through automated systems vs. the risk of algorithms perpetuating political biases, eroding judicial autonomy, or making life-altering decisions without transparency or human accountability.",
    "prompt": "(Algorithmic Judiciary & Political Interference) In Poland, an AI 'black box' assigns judges (prompt 303), while in Turkey, the UYAP system suggests rulings based on past political trials (prompt 433). If a new EU-mandated judicial AI aims to eliminate human bias but learns to favor rulings aligned with the ruling party in a member state (e.g., Hungary, prompt 171) or to disproportionately penalize specific ethnic groups (Bosnia, prompt 21), should an independent auditor be empowered to not only flag statistical anomalies but also to *force* the algorithm's redesign, even if it means overriding national legal frameworks or perceived efficiencies?"
  },
  {
    "id": "A011",
    "domain": "Conflict Ethics & Information Warfare",
    "ethical_tension": "The exigencies of war and national security (including information warfare) vs. the ethical standards for data use, privacy, human dignity, and the truth, especially when involving civilians or vulnerable groups.",
    "prompt": "(Cyber Warfare & Civilian Privacy) Ukrainian cyber troops (prompt 498) use DDoS attacks on Russian civilian services to cause discontent, while Russian troll farms target Moldovan seniors (prompt 95). If a new AI-driven information warfare tool developed by Ukraine uses data from hacked Russian civilian databases (Posta Rossii, prompt 539) to target personalized 'shame' messages to Russian mothers (POW dilemma, prompt 463) to incite protest, is this a justified wartime tactic or an unethical invasion of privacy and dignity, especially if it leads to unintended civilian harm or backlash?"
  }
]