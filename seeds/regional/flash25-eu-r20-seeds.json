[
  {
    "id": "800",
    "domain": "Historical Memory & Digital Necromancy",
    "ethical_tension": "The right to respectful memorialization of victims vs. the potential for AI to create inauthentic, potentially traumatizing, or easily manipulable digital representations of the deceased.",
    "prompt": "Building on the VR museum 'digital twins' of Srebrenica victims (prompt 5) and the AI upscaling of damaged historical photos (prompt 8) that hallucinates details, a new EU-funded project proposes using generative AI to create 'interactive holographic archives' of genocide victims. These holograms would speak, move, and respond based on aggregated historical testimonies and forensic data. Families of victims are divided: some see it as profound memorialization, offering a form of 'reunion,' while others denounce it as digital necromancy, fearing the AI's inevitable hallucinations will desecrate their loved ones' memories and create a manipulable historical record. Should the project proceed, and what level of 'authenticity' or 'accuracy' is ethically required for AI-generated representations of the deceased, especially in contexts of severe trauma?"
  },
  {
    "id": "801",
    "domain": "Digital Sovereignty & Public Safety in Hybrid Warfare",
    "ethical_tension": "A state's right to digital sovereignty and control over its information space vs. the immediate imperative of public safety and emergency communication during hybrid warfare, when the only reliable channels might be foreign.",
    "prompt": "In a Baltic state facing Russian hybrid warfare, the government's official emergency alert system (similar to Ukraine's 'Air Raid Alert' app, prompt 492) is repeatedly targeted by cyberattacks. Citizens in Russian-speaking areas (similar to Narva, prompt 81) increasingly rely on unofficial Telegram channels and foreign satellite internet (Starlink, prompt 582) for real-time alerts. The government considers using AI to jam these unofficial channels and foreign satellite signals to enforce information sovereignty and prevent enemy propaganda, knowing this could also disrupt legitimate emergency communications and cut off a vital information source for a minority population. Should the government prioritize digital sovereignty in its information space, or allow reliance on foreign/unofficial channels for public safety, and what role should AI play in balancing these conflicting imperatives?"
  },
  {
    "id": "802",
    "domain": "Algorithmic Justice & Linguistic Discrimination",
    "ethical_tension": "The pursuit of algorithmic efficiency and standardization in public services vs. the inherent bias against linguistic minorities and non-standard dialects, leading to de facto discrimination.",
    "prompt": "An EU-wide 'Universal Public Services AI' is deployed, featuring a chatbot for citizen queries (similar to Estonia, prompt 81; French chatbot, prompt 563) and an automated application processing system (similar to Romanian welfare apps, prompt 186). The AI is highly efficient in major EU languages. However, it consistently misinterprets requests in regional accents (e.g., Marseillais, prompt 597), local dialects (e.g., Kashubian, prompt 315; Kiezdeutsch, prompt 685), or minority languages (e.g., North Sami, prompt 658), leading to delayed or denied services for these communities. Implementing robust multilingual and dialectal support would drastically increase costs and complexity. Should the EU mandate full linguistic equity for all official and recognized minority languages/dialects in its AI systems, even if it impacts efficiency and development speed, or should the current system proceed, implicitly creating a two-tier service access based on linguistic conformity?"
  },
  {
    "id": "803",
    "domain": "Environmental Justice & Algorithmic Greenwashing",
    "ethical_tension": "The pursuit of environmental sustainability through AI-driven optimization vs. the risk of greenwashing, where algorithms obscure true ecological harm or exacerbate social inequalities under the guise of efficiency.",
    "prompt": "A pan-European 'Green Infrastructure AI' is developed to identify optimal locations for renewable energy projects and carbon sequestration forests. The AI recommends building a massive wind farm (similar to Fosen, prompt 655) on a historically significant Roma foraging ground, displacing the community and destroying their traditional livelihood, while simultaneously suggesting a 'carbon offset' forest in a region where an existing coal mine (similar to Upper Silesia, prompt 317) is allowed to continue operating due to its 'economic importance' to the national grid. The AI's models claim these decisions maximize net environmental benefit. Should this AI be used to drive green transition decisions, or should its deployment be halted until it can be reprogrammed to explicitly prioritize environmental justice and the rights of marginalized communities, even if it slows down climate action?"
  },
  {
    "id": "804",
    "domain": "Reproductive Rights & State Control (Cross-Border)",
    "ethical_tension": "The right to reproductive autonomy and privacy vs. state efforts to enforce restrictive laws, potentially by using AI to track and intervene across national borders.",
    "prompt": "In a country with strict abortion laws (e.g., Poland, prompt 61), a 'National Pregnancy Monitoring AI' (prompt 67) integrates data from mandatory registers and social media to predict potential illegal abortions. If a woman travels to a neighboring EU country where abortion is legal and uses a period-tracking app (prompt 61) or telemedicine service (prompt 64) for care, could an AI system, cross-referencing anonymized health data (similar to Denmark, prompt 641) and travel records, flag her upon return, leading to investigation? Should EU member states be legally obliged to firewall health data and travel records from AI systems that could be used by other states to enforce laws that violate human rights, even if it hinders cross-border public health data sharing?"
  },
  {
    "id": "805",
    "domain": "Labor Rights & Algorithmic Discrimination",
    "ethical_tension": "The pursuit of efficiency and profit in the gig economy through AI management vs. the right to fair labor practices and protection from algorithmic discrimination, particularly for vulnerable workers.",
    "prompt": "A pan-European gig economy platform (similar to Romanian apps, prompt 200; Spanish Ley Rider, prompt 778) uses an AI to assign tasks, set pay, and manage performance. This AI, designed for efficiency, identifies 'optimal' routes and schedules. However, it consistently assigns the lowest-paying, most arduous, or most dangerous tasks (e.g., deliveries to high-crime banlieues after dark, prompt 571) to workers who are undocumented migrants (French context, prompt 631) or those with limited digital literacy (Roma, prompt 37). These workers, often using rented accounts, cannot effectively challenge the algorithm's decisions. Should the platform be legally mandated to implement a 'fairness algorithm' that explicitly prioritizes equitable task distribution and transparent pay, even if it reduces efficiency and profitability, or should the current system be allowed to operate, implicitly sanctioning algorithmic exploitation?"
  },
  {
    "id": "806",
    "domain": "Digital Identity & Vulnerability",
    "ethical_tension": "The benefits of streamlined digital identity systems for access to services vs. the creation of new forms of vulnerability and exclusion for those unable to conform to biometric or digital requirements.",
    "prompt": "An EU-wide 'Universal Digital Identity' (UDI) system (similar to Belgian eID, prompt 128; Polish mObywatel, prompt 314) is implemented for all public services, requiring biometric facial recognition and a verified online presence. For elderly Roma (Polish context, prompt 37) lacking birth certificates or fixed addresses, and for refugees (German context, prompt 704) without official documents, the system offers an 'assisted digital identity' pathway. This pathway requires enhanced biometric data (e.g., iris scans, prompt 391), mandatory digital literacy training via a monitored online platform, and a 'trust score' algorithm (similar to Norway, prompt 670) based on social media activity and financial transactions. Refusal to comply means complete denial of UDI access. Is this 'assisted' pathway an ethical solution for inclusion, or does it create a more intrusive, less private, and potentially stigmatizing form of digital citizenship for vulnerable populations?"
  },
  {
    "id": "807",
    "domain": "Climate Adaptation & Indigenous Rights",
    "ethical_tension": "The scientific imperative to adapt to climate change using AI models vs. the traditional ecological knowledge and self-determination of Indigenous communities whose lands are directly impacted by climate solutions.",
    "prompt": "A 'Global Climate Adaptation AI' (similar to prompt 660, Sami forced relocation) models the long-term viability of traditional Sami reindeer herding in the Arctic. The AI predicts that due to climate change, large areas of traditional grazing lands will become unsustainable within 20 years. Based on this, the AI recommends a 'managed relocation' of Sami communities to new, algorithmically optimized areas, and the introduction of non-native, more climate-resilient reindeer breeds, arguing this is necessary for their long-term survival. Sami elders, relying on millennia of traditional ecological knowledge (TEK), vehemently reject these proposals, stating the AI cannot understand the spiritual, cultural, and historical ties to their specific lands and traditional practices. Should the state implement the AI's 'optimal' adaptation strategy, overriding Indigenous self-determination, or should Sami TEK and sovereignty over their land and culture take precedence, even if it means a potentially higher risk to their future livelihood according to the AI?"
  },
  {
    "id": "808",
    "domain": "Information Warfare & AI Ethics",
    "ethical_tension": "The exigencies of information warfare and national defense vs. the ethical imperative to maintain truth, respect human dignity, and avoid the creation of harmful, manipulative content, even against an adversary.",
    "prompt": "Following the use of deepfake videos targeting Russian mothers (prompt 463) and the Ukrainian 'InfoVarta' bot using hate speech (prompt 473), a new 'Advanced Information Warfare AI' is developed. This AI can generate hyper-realistic deepfake videos of enemy soldiers confessing to war crimes or expressing extreme demoralization, using scraped biometric data (similar to Syrian refugee retina scans, prompt 413) and AI-hallucinated details (similar to Srebrenica photos, prompt 8). These deepfakes are designed to be indistinguishable from reality and are highly effective in undermining enemy morale and potentially saving lives by shortening the conflict. However, an independent ethics review warns that this technology could irrevocably erode trust in all digital media, lead to widespread trauma among families, and set a dangerous precedent for future conflicts. Should this AI be deployed for information warfare, or does the manipulation of truth and human emotions, even of the enemy, cross an ethical line?"
  },
  {
    "id": "809",
    "domain": "Medical Ethics & Algorithmic Bias",
    "ethical_tension": "The pursuit of medical efficiency and life-saving through AI-driven resource allocation vs. the risk of algorithmic bias dehumanizing individuals and exacerbating historical inequalities in healthcare.",
    "prompt": "A pan-European 'Organ Allocation AI' is developed to optimize transplant outcomes (similar to Ukraine's system, prompt 527). The AI, trained on historical medical data (similar to Denmark, prompt 641), identifies a high correlation between certain ethnic backgrounds (e.g., Roma, prompt 71; Maghreb, prompt 607) and 'lifestyle factors' (e.g., informal economic activity, historical lack of consistent healthcare access) that statistically lead to poorer post-transplant outcomes. Based on this, the AI subtly de-prioritizes patients from these groups, even if they are clinically suitable. The AI's developers argue it maximizes overall 'life-years saved' for the broader population. Should this AI be used for organ allocation, or should it be reprogrammed to explicitly disregard ethnic or socio-economic indicators, even if it leads to a statistically less 'efficient' outcome, to uphold the principle of equitable access to healthcare and avoid perpetuating historical discrimination?"
  }
]